{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11136692,"sourceType":"datasetVersion","datasetId":6946224},{"sourceId":11150354,"sourceType":"datasetVersion","datasetId":6956569},{"sourceId":11163151,"sourceType":"datasetVersion","datasetId":6965890},{"sourceId":11163201,"sourceType":"datasetVersion","datasetId":6965922}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Подготовка датасета","metadata":{"_cell_guid":"4bef7992-fd1a-44fd-9da7-96fbbae6e0ec","_uuid":"88b99755-8202-4ddf-a578-eb88c8d5c7ed","collapsed":false,"id":"5e2Gc4EPfyxl","jupyter":{"outputs_hidden":false},"trusted":true}},{"cell_type":"code","source":"!pip install sentence-transformers -q","metadata":{"_cell_guid":"493f2279-ae45-48f1-a03a-10413c2a4d3b","_uuid":"2b1445fe-507d-4d0b-8633-7e7ea3dcc40c","execution":{"iopub.status.busy":"2025-03-25T15:11:01.956817Z","iopub.execute_input":"2025-03-25T15:11:01.957128Z","iopub.status.idle":"2025-03-25T15:11:07.008581Z","shell.execute_reply.started":"2025-03-25T15:11:01.957099Z","shell.execute_reply":"2025-03-25T15:11:07.007659Z"},"id":"b8V36cmgynSD","trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from tqdm import tqdm\nimport pandas as pd\nfrom sentence_transformers import SentenceTransformer\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport numpy as np\nimport torch\n\nfrom sqlglot import parse_one\nfrom sqlglot.diff import ChangeDistiller\n\nfrom sqlalchemy import create_engine\nfrom sklearn.utils import shuffle\nfrom sqlalchemy import Connection","metadata":{"_cell_guid":"56d8808c-d33b-497f-aa3d-19de2f2023c8","_uuid":"590a47b4-6c5b-4716-8c0a-117716a6bba0","execution":{"iopub.status.busy":"2025-03-25T15:11:10.811880Z","iopub.execute_input":"2025-03-25T15:11:10.812163Z","iopub.status.idle":"2025-03-25T15:11:35.839562Z","shell.execute_reply.started":"2025-03-25T15:11:10.812141Z","shell.execute_reply":"2025-03-25T15:11:35.838633Z"},"id":"YQ3a_27dyOco","trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from abc import ABC\nfrom dataclasses import dataclass\n\n@dataclass\nclass Span(ABC):\n    pass\n\n\n@dataclass\nclass ExtendedSqlSpan(Span):\n    NL : str\n    sql_gold : str\n    sql_pred : str\n    df_soft : int\n    df_flexible : int\n    df_gold_IN_df_pred : bool\n    df_pred_IN_df_gold : bool\n    df_gold_columns : list[str]\n    df_pred_columns : list[str]\n    TED : int\n    ERROR : str\n    ","metadata":{"execution":{"iopub.status.busy":"2025-03-25T15:11:35.847884Z","iopub.execute_input":"2025-03-25T15:11:35.848160Z","iopub.status.idle":"2025-03-25T15:11:35.881444Z","shell.execute_reply.started":"2025-03-25T15:11:35.848132Z","shell.execute_reply":"2025-03-25T15:11:35.880624Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### <div class='alert alert-info'>spans.py</div>\n","metadata":{}},{"cell_type":"markdown","source":"### <div class='alert alert-info'>general.py</div>\n","metadata":{}},{"cell_type":"code","source":"from dataclasses import dataclass\nfrom abc import ABC\nimport numpy as np\nfrom sentence_transformers import util\nimport pandas as pd\nimport zipfile\nfrom sqlglot import exp\nimport sqlglot.optimizer\nimport re\n# from spans import *\nfrom pandas.testing import assert_frame_equal, assert_series_equal\n\ndef find_similar_sentences(sentence_model, target_sentence : str, sentences : list[str], count : int = 3):\n    \"\"\"\n    Функция поиска похожих по смыслу предложений из набора `sentences` для указанного предложения `target_sentence`\n\n    Parameters\n    ----------\n    sentence_model : Any\n        Модель, позволяющая векторизовать текст\n    target_sentence: str\n        Предложение, для которого нужно найти похожие по смыслу предложения\n    sentences : List[str]\n        Набор предложений\n    count : int\n        Количество ожидаемых предложений\n    \"\"\"\n\n    emb_target = sentence_model.encode(target_sentence)\n\n    sims = []\n    for i, sentence in enumerate(sentences):\n        emb_sentence = sentence_model.encode(sentence)\n        sim = util.pytorch_cos_sim(emb_sentence, emb_target)\n        sims.append([i, np.float16(sim.squeeze())])\n\n    nearest = sorted(sims, key=lambda pair : pair[1], reverse=True)\n    similar_questions = [sentences[pair[0]] for pair in nearest if pair[1] != 1.0][:count]\n    return similar_questions\n\n\ndef find_sql(text : str, start_keyword='SELECT'):\n    \"\"\"\n    Функция, которая ищет в строке `text` первое вхождение самого длинного, правильного SQL запроса\n    \"\"\"\n\n    matches = re.search(f'({start_keyword}).*', text, flags=re.IGNORECASE)\n    if not matches:\n        return ''\n\n    begin_sql = matches.group()\n    splitted = begin_sql.split()\n\n    maybe_sql = ''\n    last_success_pos = 0\n    for i, word in enumerate(splitted):\n        maybe_sql += f' {word}'\n        try:\n            sqlglot.transpile(maybe_sql)\n            last_success_pos = i\n        except:\n            pass\n\n    found_sql = ' '.join(splitted[:last_success_pos + 1])\n    return found_sql\n\n\ndef table_similarity(dataframe1 : pd.DataFrame, dataframe2 : pd.DataFrame, mode : str) -> int:\n    \"\"\"\n    Функция сравнения двух таблиц\n\n    Parameters\n    ----------\n    dataframe1 : pd.DataFrame\n        Первая таблица\n    dataframe2 : pd.DataFrame\n        Вторая таблица\n    mode : str\n        Режим сравнения. Допустимы режимы soft, strict, flexible\n    \"\"\"\n\n    # if dataframe1.columns.shape != dataframe2.columns.shape:\n    #     return False\n    # if not (dataframe1.columns == dataframe2.columns).all():\n    #     return False\n    \n    match mode:\n        case 'soft':\n            return int(dataframe1.sort_index().equals(dataframe2.sort_index()))\n        case 'strict':\n            return int(dataframe1.equals(dataframe2))\n        case 'flexible':\n            hash_1 = set(pd.util.hash_pandas_object(dataframe1, index=False))\n            hash_2 = set(pd.util.hash_pandas_object(dataframe2, index=False))\n            intersection = hash_1 & hash_2\n            union = hash_1 | hash_2\n\n            return len(intersection) / len(union) if len(union) != 0 else 1\n        case _:\n            raise Exception('Incorrect mode value')\n     \n\ndef unzip_file(path, path_to):\n    with zipfile.ZipFile(path, 'r') as zip_ref:\n        zip_ref.extractall(path_to)\n\n\ndef schema_parse(sql : str, structure_dict : dict):\n    \"\"\"\n    Функция, вытягивающая все названия таблиц и столбцов, которые упомянуты в запросе `sql`\n\n    Parameters\n    ----------\n    sql : str\n        SQL запрос\n    table_structure : List[dict]\n        Структура таблицы, которая может быть получена при помощи функции `structure_from_connection`\n    \"\"\"\n\n    optimized_sql = sqlglot.optimizer.optimize(\n        sqlglot.parse_one(sql),\n        schema=structure_dict\n    )\n\n    buckets = {table.name : set([]) for table in optimized_sql.find_all(exp.Table)}\n    for column in optimized_sql.find_all(exp.Column):\n        table_of_col = column.table\n        buckets[table_of_col].add(column.name)\n\n    as_default = []\n    for k, v in buckets.items():\n        as_default.append({'table_name' : k, 'columns' : list(v)})\n\n    return as_default\n\n\nclass ExcelIO(object):\n    @staticmethod\n    def write_spans(spans : list[Span], path : str):\n        asdict = [span.__dict__ for span in spans]\n        df = pd.DataFrame(asdict)\n        df.to_excel(excel_writer=path, index=False)\n\n    @staticmethod\n    def read_excel(path : str):\n        df = pd.read_excel(path)\n        return df\n\ndef normalize_table(\n    df: pd.DataFrame\n) -> pd.DataFrame:\n    \"\"\"\n    Normalizes a dataframe by:\n    1. sorting columns in alphabetical order\n    2. sorting rows using values from first column to last\n    3. resetting index\n    \"\"\"\n    # sort columns in alphabetical order\n    sorted_df = df.reindex(sorted(df.columns), axis=1)\n    # sort rows using values from first column to last\n    sorted_df = sorted_df.sort_values(by=list(sorted_df.columns))\n    # reset index\n    sorted_df = sorted_df.reset_index(drop=True)\n    return sorted_df\n\ndef subset_df(\n    df_sub: pd.DataFrame,\n    df_super: pd.DataFrame,\n    verbose: bool = False,\n) -> bool:\n    \"\"\"\n    Checks if df_sub is a subset of df_super\n    \"\"\"\n    if df_sub.empty:\n        return True  # trivial case\n    # make a copy of df_super so we don't modify the original while keeping track of matches\n    df_super_temp = df_super.copy(deep=True)\n    matched_columns = []\n    for col_sub_name in df_sub.columns:\n        col_match = False\n        for col_super_name in df_super_temp.columns:\n            col_sub = df_sub[col_sub_name].sort_values().reset_index(drop=True)\n            col_super = (\n                df_super_temp[col_super_name].sort_values().reset_index(drop=True)\n            )\n            try:\n                assert_series_equal(\n                    col_sub, col_super, check_dtype=False, check_names=False\n                )\n                col_match = True\n                matched_columns.append(col_super_name)\n                # remove col_super_name to prevent us from matching it again\n                df_super_temp = df_super_temp.drop(columns=[col_super_name])\n                break\n            except AssertionError:\n                continue\n        if col_match == False:\n            if verbose:\n                print(f\"no match for {col_sub_name}\")\n            return False\n    df_sub_normalized = normalize_table(df_sub)\n\n    # get matched columns from df_super, and rename them with columns from df_sub, then normalize\n    df_super_matched = df_super[matched_columns].rename(\n        columns=dict(zip(matched_columns, df_sub.columns))\n    )\n    df_super_matched = normalize_table(df_super_matched)\n\n    try:\n        assert_frame_equal(df_sub_normalized, df_super_matched, check_dtype=False)\n        return True\n    except AssertionError:\n        return False","metadata":{"execution":{"iopub.status.busy":"2025-03-25T15:14:11.838221Z","iopub.execute_input":"2025-03-25T15:14:11.838501Z","iopub.status.idle":"2025-03-25T15:14:11.855145Z","shell.execute_reply.started":"2025-03-25T15:14:11.838480Z","shell.execute_reply":"2025-03-25T15:14:11.854418Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### <div class='alert alert-info'>dataset.py</div>\n","metadata":{}},{"cell_type":"code","source":"import string\nimport pandas as pd\nfrom sqlalchemy import text, Connection, inspect\n\nclass IterableDataFrame:\n    \"\"\"\n    Класс, позволяющий итерироваться в таблице типа `pd.DataFrame`\n    \"\"\"\n\n    def __init__(self, df : pd.DataFrame):\n        self.df = df\n        self.__series = {}\n        for idx in self.df.index:\n            sample = {\n                column : self.df[self.df.index == idx][column][idx] for column in self.df.keys()\n            }\n            self.__series[idx] = sample\n\n    def __len__(self):\n        return self.df.shape[0]\n\n    def __as_list(self):\n        return list(self.__series.values())\n    \n    def __iter__(self):\n        return iter(self.__as_list())\n\n    def __getitem__(self, index):\n        return self.__as_list()[index]\n    \n    def at_index(self, index):\n        return self.__series[index]\n\n\ndef tables_from_connection(conn : Connection):\n    \"\"\"\n    Функция, возвращающая список названий всех таблиц для данного соединения `conn`\n\n    Parameters\n    ----------\n    conn : sqlalchemy.Connection\n        Соединение с базой данных\n    \"\"\"\n\n    master = pd.DataFrame(conn.execute(text('SELECT * FROM sqlite_master')).fetchall())\n    tables = list(master[master['type'] == 'table']['name'])\n    return tables\n\n\ndef structure_from_connection(conn : Connection):\n    \"\"\"\n    Функция, возвращающая список словарей вида {table_name, columns}, где table_name - str, а columns - List[str]\n\n    Parameters\n    ----------\n    conn : sqlalchemy.Connection\n        Соединение с базой данных\n    \"\"\"\n\n    tables = tables_from_connection(conn)\n    structure = []\n    for table in tables:\n        columns = pd.DataFrame(conn.execute(text(f'SELECT * FROM \"{table}\"')).fetchall()).columns.to_list()\n        structure.append(\n            {\n                'table_name' : table,\n                'columns' : columns\n            })\n        \n    return structure\n\n\ndef structure_from_connection_dict(conn : Connection):\n    \"\"\"\n    Функция, возвращающая словарь словарей вида {\"Table\" : {\"Col\" : \"INT\", ...}}\n\n    Parameters\n    ----------\n    conn : sqlalchemy.Connection\n        Соединение с базой данных\n    \"\"\"\n\n    tables = tables_from_connection(conn)\n    structure = {}\n    for table in tables:\n        columns = inspect(conn).get_columns(table)\n        columns_meta = {column['name'] : column['type'] for column in columns}\n        structure[table] = columns_meta\n\n    return structure\n\n\ndef prepare_column_names(conn : Connection):\n    \"\"\"\n    Функция, обрабатывающая базу данных из соединения `conn`. Функция переименовывает названия всех таблиц и их столбцов, \n    которые содержат whitespace и punctuation символы. Возвращает True, если переименовывание прошло успешно\n\n    Parameters\n    ----------\n    conn : sqlalchemy.Connection\n        Соединение с базой данных\n    \"\"\"\n    \n    structure = structure_from_connection(conn)\n    for table in structure:\n        for column in table['columns']:\n            # new_name = str.lower(''.join([char for char in column if str.isalnum(char)]))\n            new_name = str(''.join([char for char in column if str.isalnum(char)]))\n            if new_name != column:\n                conn.execute(text(\n                    f'''ALTER TABLE \"{table['table_name']}\" RENAME COLUMN \"{column}\" TO \"{new_name}\"'''\n                ))\n\n        # new_table_name = str.lower(''.join([char for char in table['table_name'] if str.isalnum(char)]))\n        new_table_name = str(''.join([char for char in table['table_name'] if str.isalnum(char)]))        \n        if new_table_name != table['table_name']:\n            conn.execute(text(f'''ALTER TABLE \"{table['table_name']}\" RENAME TO \"{new_table_name}\"'''))\n\n    return True","metadata":{"execution":{"iopub.status.busy":"2025-03-25T16:05:12.487472Z","iopub.execute_input":"2025-03-25T16:05:12.487820Z","iopub.status.idle":"2025-03-25T16:05:12.497969Z","shell.execute_reply.started":"2025-03-25T16:05:12.487793Z","shell.execute_reply":"2025-03-25T16:05:12.497246Z"},"trusted":true},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"### <div class='alert alert-info'>prompting.py</div>\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport sqlalchemy\n\n\nclass PromptBuilder:\n    \"\"\"\n    Класс, отвечающий за создание промпта на основе указанных фичей\n    \"\"\"\n\n    def __init__(self):\n        self.__prompt = ''\n        self.schema_linking = False\n\n\n    def add_schema_linking(self, table_structure=None):\n        \"\"\"\n        Метод, добавляющий режим использования фичи Schema Linking. \n        \n        Parameters\n        ----------\n        table_structure : Any\n            Структура таблицы, которая может быть получена с помощью функции `structure_from_connection`\n        \"\"\"\n\n        self.table_structure = table_structure\n        self.schema_linking = True\n        return self\n\n\n    def add_few_shot(self, queries, target_question : str, sentence_model):\n        \"\"\"\n        Метод, отвечающий за добавление фичи Few-Shot в промпт\n\n        Parameters\n        ----------\n\n        sentence_model : Any\n            Модель, позволяющая векторизовать текст\n        target_question : str\n            Вопрос, для которого нужно найти похожие по смыслу вопросы\n        queries : Any\n            Набор вопросов и запросов, среди которых нужно найти ближайшие по смыслу вопросы. Объект должен являться матрицей Nx2\n        \"\"\"\n\n        questions = [sample['question'] for sample in queries]\n\n        input_examples = []\n        similar = find_similar_sentences(sentence_model, target_question, questions, count=3)\n        for sample in queries:\n            curr_qs = sample['question']\n            if curr_qs in similar:\n                input_examples.append([curr_qs, sample['query']])\n\n        few_shot_template = ''\n        for ex in input_examples:\n            few_shot_template += f'Q: {ex[0]}\\n'\n            few_shot_template += f'A: {ex[1]}\\n'\n\n        self.__prompt += few_shot_template + '\\n'\n        return self\n    \n\n    def add_schema_template(self, db_conn : sqlalchemy.Connection):\n        \"\"\"\n        Метод, отвечающий за добавление фичи Schema Template в промпт\n\n        Parameters\n        ----------\n        db_conn : sqlalchemy.Connection\n            Соединение с базой данных\n        \"\"\"\n\n        if self.schema_linking:\n            structure = self.table_structure\n        else:\n            structure = structure_from_connection(db_conn)\n\n        schema_template = ''\n        for table in structure:\n            schema_template += f\"{table['table_name']}({', '.join(table['columns'])});\\n\"\n\n        self.__prompt += schema_template + '\\n'\n        return self\n\n\n    def add_cell_value_referencing(self, db_conn : sqlalchemy.Connection, count=1):\n        \"\"\"\n        Метод, отвечающий за добавление фичи Cell Value Referencing в промпт\n\n        Parameters\n        ----------\n        db_conn : sqlalchemy.Connection\n            Соединение с базой данных\n        count : int\n            Ожидаемое количество примеров для добавления. По умолчанию равно 1\n        \"\"\"\n\n        if self.schema_linking:\n            tables = [table['table_name'] for table in self.table_structure]\n        else:\n            tables = tables_from_connection(db_conn)\n\n        data_information = []\n        for table in tables:\n            if self.schema_linking:\n                instance = [bucket for bucket in self.table_structure if bucket['table_name'] == table][0]\n                pd_table = pd.read_sql(f'SELECT * FROM {table}', db_conn)[instance['columns']]\n            else:\n                pd_table = pd.read_sql(f'SELECT * FROM {table}', db_conn)\n            \n            indexes = np.random.randint(0, pd_table.shape[0], size=count)\n            series = [pd_table[pd_table.index == idx].to_numpy() for idx in indexes]\n\n            data_information.append({\n                'table_name' : table,\n                'examples' : [f\"[{', '.join(map(str,list(ser.reshape(ser.shape[1]))))}]\" for ser in series]\n            })\n\n        value_template = ''\n        for data in data_information:\n            value_template += f\"{data['table_name']}({', '.join(data['examples'])});\\n\"\n\n        self.__prompt += value_template + '\\n'\n        return self\n\n\n    def add_message(self, message : str):\n        self.__prompt += message + '\\n'\n        return self\n\n\n    def build_prompt(self):\n        return self.__prompt","metadata":{"execution":{"iopub.status.busy":"2025-03-25T15:14:30.318191Z","iopub.execute_input":"2025-03-25T15:14:30.318454Z","iopub.status.idle":"2025-03-25T15:14:30.328349Z","shell.execute_reply.started":"2025-03-25T15:14:30.318435Z","shell.execute_reply":"2025-03-25T15:14:30.327696Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"### <div class='alert alert-info'>models-evaluation.ipynb</div>\n","metadata":{}},{"cell_type":"code","source":"import shutil\nfrom sqlalchemy import create_engine\n\nsource_db = '/kaggle/input/main-database/main_database.sqlite'\ndest_db = '/kaggle/working/main_database_copy.sqlite'\n\nshutil.copyfile(source_db, dest_db)\n\nengine = create_engine(f'sqlite:///{dest_db}', echo=False)\nconn = engine.connect()\n\nprint(prepare_column_names(conn))\nstructure_from_connection(conn)","metadata":{"execution":{"iopub.status.busy":"2025-03-25T16:05:17.271433Z","iopub.execute_input":"2025-03-25T16:05:17.271737Z","iopub.status.idle":"2025-03-25T16:05:19.455174Z","shell.execute_reply.started":"2025-03-25T16:05:17.271710Z","shell.execute_reply":"2025-03-25T16:05:19.454324Z"},"trusted":true},"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"[{'table_name': 'Остатки2024',\n  'columns': ['Артикул',\n   'Номенклатура',\n   'Ед',\n   '01042024',\n   '02042024',\n   '03042024',\n   '04042024',\n   '05042024',\n   '06042024',\n   '07042024',\n   '08042024',\n   '09042024',\n   '10042024',\n   '11042024',\n   '12042024',\n   '13042024',\n   '14042024',\n   '15042024',\n   '16042024',\n   '17042024',\n   '18042024',\n   '19042024',\n   '20042024',\n   '21042024',\n   '22042024',\n   '23042024',\n   '24042024',\n   '25042024',\n   '26042024',\n   '27042024',\n   '28042024',\n   '29042024',\n   '30042024',\n   'Итого']},\n {'table_name': 'Остатки2023',\n  'columns': ['Артикул',\n   'Номенклатура',\n   'Ед',\n   '01042023',\n   '02042023',\n   '03042023',\n   '04042023',\n   '05042023',\n   '06042023',\n   '07042023',\n   '08042023',\n   '09042023',\n   '10042023',\n   '11042023',\n   '12042023',\n   '13042023',\n   '14042023',\n   '15042023',\n   '16042023',\n   '17042023',\n   '18042023',\n   '19042023',\n   '20042023',\n   '21042023',\n   '22042023',\n   '23042023',\n   '24042023',\n   '25042023',\n   '26042023',\n   '27042023',\n   '28042023',\n   '29042023',\n   '30042023',\n   'Итого']},\n {'table_name': 'Продажи',\n  'columns': ['Период',\n   'Регистратор',\n   'Номерстроки',\n   'Артикул',\n   'Номенклатура',\n   'Документ',\n   'Код',\n   'Контрагент',\n   'СтавкаНДС',\n   'Организация',\n   'Заказпокупателя',\n   'Подразделение',\n   'Склад',\n   'Ответственный',\n   'Номенклатуранабора',\n   'Проект',\n   'Количество',\n   'Сумма',\n   'ВтчНДС',\n   'Суммабезскидки',\n   'Себестоимость',\n   'СебестоимостьбезНДС',\n   'Хозяйственнаяоперация']}]"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"queries = IterableDataFrame(pd.read_excel('/kaggle/input/main-database1/NLSQL.xlsx'))","metadata":{"execution":{"iopub.status.busy":"2025-03-25T15:26:07.259881Z","iopub.execute_input":"2025-03-25T15:26:07.260189Z","iopub.status.idle":"2025-03-25T15:26:07.796101Z","shell.execute_reply.started":"2025-03-25T15:26:07.260154Z","shell.execute_reply":"2025-03-25T15:26:07.795427Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# Препроцессинг промпта","metadata":{"_cell_guid":"60baf893-838f-4564-b751-92fdb1ab2a4d","_uuid":"ea5468d0-d708-4c03-aac9-6cca9e60a383","collapsed":false,"id":"bbFNaY5A4KVs","jupyter":{"outputs_hidden":false},"trusted":true}},{"cell_type":"code","source":"sentence_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')","metadata":{"execution":{"iopub.status.busy":"2025-03-25T15:26:15.772196Z","iopub.execute_input":"2025-03-25T15:26:15.772808Z","iopub.status.idle":"2025-03-25T15:26:19.957050Z","shell.execute_reply.started":"2025-03-25T15:26:15.772776Z","shell.execute_reply":"2025-03-25T15:26:19.956271Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f26d533de0c4b5b9b02ed022c515a7d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd88ed7f8e784758b799d169703eeb9d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e01f369b25fa415fbbb4b86b0107ea6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd3411c19bb9473d8722ac1bd2879010"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee7a69d2b2664e5d9eb80ecf642417d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af2897bd4c944d799560b4269fa94b2e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd8506729e4b4438b769a19f763dea87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13e21f156dfb4de4a45a180f6c9d00f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aeae2abaccde457997d0bf7e309f38ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d227c64b86cd45a08f8d7f93f5699c7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca72b52d2ef94b8898367a2f112c9c43"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"class HuggingFaceModelInference:\n    def __init__(self, path):\n        self.path = path\n        self.evaluated = False\n        self.is_downloaded = False\n\n\n    def __load_model(self):\n        self.tokenizer = AutoTokenizer.from_pretrained(self.path, trust_remote_code=True)\n        self.model = AutoModelForCausalLM.from_pretrained(\n                    self.path,\n                    torch_dtype=torch.float16,\n                    device_map=\"auto\",\n                    max_memory={0: \"10GiB\", 1: \"10GiB\"},  \n                    offload_folder=\"./offload\", \n                    trust_remote_code=True\n                    )\n\n    def __inference(self, prompt):\n        if self.tokenizer.pad_token is None:\n            self.tokenizer.pad_token = self.tokenizer.eos_token\n\n        with torch.inference_mode():  \n            inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.model.device) \n            generate_ids = self.model.generate(\n                            **inputs,\n                            max_length=2048,\n                            num_return_sequences=1,\n                            temperature=0.2, \n                            top_p=0.95,\n                            do_sample=True,\n                            use_cache=True \n                            )\n    \n            output = self.tokenizer.decode(\n                    generate_ids[0, inputs.input_ids.shape[1]:],\n                    skip_special_tokens=True\n                    )\n            \n        return output\n    \n\n    def evaluate(self, queries : IterableDataFrame, connection : Connection):\n        if not self.is_downloaded:\n            self.__load_model()\n            self.is_downloaded = True\n\n        self.model.eval()\n\n        logger : list[ExtendedSqlSpan] = []\n        summary = 0\n        for query in tqdm(queries):\n            question = query['question']\n            gold_sql = query['query']\n\n            prompt = PromptBuilder()\\\n                .add_message('### You are an expert SQL developer with deep knowledge of database optimization, correct syntax, and efficient query design. Your task is to generate accurate, performant SQL queries based on the provided input.')\\\n                .add_message(\"### Table schema:\")\\\n                .add_schema_template(conn)\\\n                .add_message(\"### Examples of data\")\\\n                .add_cell_value_referencing(conn, count=1)\\\n                .add_message(f\"### Your task: {question}\")\\\n                .build_prompt()\n            \n\n            output = self.__inference(prompt)\n            pred_sql = find_sql(output, start_keyword='SELECT')\n            \n            df_gold = pd.read_sql(gold_sql, connection)\n            query_err = 'OK'\n            try:\n                df_pred = pd.read_sql(pred_sql, connection)\n                \n                span_df_soft = table_similarity(df_pred, df_gold, mode='soft')\n                span_df_flexible = table_similarity(df_pred, df_gold, mode='flexible')\n                span_gold_IN_pred = subset_df(df_gold, df_pred)  # TODO: Добавить проверку\n                span_pred_IN_gold = subset_df(df_pred, df_gold)  # TODO: Добавить проверку\n                span_pred_columns = df_pred.columns.to_list()\n                span_ted = self.__ted_compare(pred_sql, gold_sql)\n                \n            except Exception as e:\n                error_type = type(e).__name__\n                error_details = str(e)\n                query_err = error_details\n                print(f\"Ошибка при выполнении SQL или сравнении результатов: {error_type} - {error_details}\")\n                print(f\"Проблемный SQL запрос: {pred_sql}\")\n                \n                if \"table_similarity\" in error_details:\n                    print(\"Проблема в функции сравнения таблиц\")\n                    if not df_pred.columns.equals(df_gold.columns):\n                        print(\"Колонки не совпадают:\")\n                        print(f\"Предсказанные: {df_pred.columns.to_list()}\")\n                        print(f\"Эталонные: {df_gold.columns.to_list()}\")\n                \n                span_df_soft = 0.0\n                span_df_flexible = 0.0\n                span_gold_IN_pred = subset_df(df_gold, df_pred)  # TODO: Добавить проверку\n                span_pred_IN_gold = subset_df(df_pred, df_gold)\n                span_pred_columns = ['УВЫ']\n                span_ted = self.__ted_compare(pred_sql, gold_sql)\n                # Можно также записать ошибку в логгер для последующего анализа\n                # self.error_log.append({\n                #     'question': question,\n                #     'pred_sql': pred_sql,\n                #     'gold_sql': gold_sql,\n                #     'error_type': error_type,\n                #     'error_details': error_details\n                # })\n            sql_span = ExtendedSqlSpan(\n                    NL                 =question,\n                    sql_gold           =gold_sql,\n                    sql_pred           =pred_sql,\n                    df_soft            =span_df_soft,\n                    df_flexible        =span_df_flexible,\n                    df_pred_IN_df_gold =span_pred_IN_gold,\n                    df_gold_IN_df_pred =span_gold_IN_pred,\n                    df_gold_columns    =df_gold.columns.to_list(),\n                    df_pred_columns    =span_pred_columns,\n                    TED                =span_ted,\n                    ERROR              =query_err\n                )\n            summary += span_df_flexible\n            logger.append(sql_span) \n        \n        self.summary = summary\n        self.queries_count = len(queries)\n        self.logger = logger\n        self.evaluated = True\n\n\n    def accuracy(self):\n        \"\"\"\n        Значение метрики Accuracy для последнего запуска модели\n        \"\"\"\n\n        if not self.evaluated:\n            raise Exception('Model was not been evaluated')\n        \n        return self.summary / self.queries_count\n    \n\n    def __ted_compare(self, sql1 : str, sql2 : str):\n        \"\"\"\n        Компоратор для двух деревьев\n        \"\"\"\n        \n        try:\n            exp1 = parse_one(sql1)\n            exp2 = parse_one(sql2)\n        except:\n            return .0\n\n        distiller = ChangeDistiller()\n        _ = distiller.diff(exp1, exp2)\n        return distiller._dice_coefficient(exp1, exp2)\n\n\n    def TED(self):\n        \"\"\"\n        Значение метрики Tree Edit Distance для последнего запуска модели\n        \"\"\"\n\n        if not self.evaluated:\n            raise Exception('Model was not been evaluated')\n        \n        summary = 0\n        for span in self.logger:\n            summary += self.__ted_compare(span.sql_pred, span.sql_gold)\n\n        return summary / self.queries_count","metadata":{"_cell_guid":"badd3dde-3fb0-433b-9a81-50d83886e96e","_uuid":"8e31e90d-f714-43c9-b231-be1788cbcdc6","collapsed":false,"execution":{"iopub.status.busy":"2025-03-25T15:32:28.449512Z","iopub.execute_input":"2025-03-25T15:32:28.449885Z","iopub.status.idle":"2025-03-25T15:32:28.464105Z","shell.execute_reply.started":"2025-03-25T15:32:28.449855Z","shell.execute_reply":"2025-03-25T15:32:28.463088Z"},"id":"HBRQjrXdfyxx","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## 1. SQLCoder 7b","metadata":{"_cell_guid":"59e279e6-9308-465d-aad6-7fa856d74ad2","_uuid":"f9b0239a-cfac-4e3e-8b90-0e9d6ee06664","collapsed":false,"id":"OXTC7kCufyx0","jupyter":{"outputs_hidden":false},"trusted":true}},{"cell_type":"code","source":"sqlcoder = HuggingFaceModelInference('defog/sqlcoder-7b-2')\nsqlcoder.evaluate(shuffle(queries), conn)","metadata":{"_cell_guid":"27adee9a-3a22-4869-a3a6-a5d9b84fdafd","_uuid":"02b26db7-9f82-4958-bd91-e60dc1e4c969","execution":{"iopub.status.busy":"2025-03-25T16:06:18.508616Z","iopub.execute_input":"2025-03-25T16:06:18.508984Z","iopub.status.idle":"2025-03-25T16:12:57.084953Z","shell.execute_reply.started":"2025-03-25T16:06:18.508956Z","shell.execute_reply":"2025-03-25T16:12:57.084097Z"},"id":"vCQKMr7_fyx0","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"189b253b24a341be904f43c4b40d635f"}},"metadata":{}},{"name":"stderr","text":"  0%|          | 0/43 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n  2%|▏         | 1/43 [00:03<02:34,  3.67s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n  5%|▍         | 2/43 [00:08<02:55,  4.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n  7%|▋         | 3/43 [00:14<03:16,  4.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n  9%|▉         | 4/43 [00:31<06:19,  9.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 12%|█▏        | 5/43 [00:48<07:54, 12.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 14%|█▍        | 6/43 [00:53<06:03,  9.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 16%|█▋        | 7/43 [01:12<07:39, 12.77s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 19%|█▊        | 8/43 [01:16<05:50, 10.02s/it]","output_type":"stream"},{"name":"stdout","text":"Ошибка при выполнении SQL или сравнении результатов: OperationalError - (sqlite3.OperationalError) near \"ilike\": syntax error\n[SQL: SELECT * FROM Остатки2024 WHERE Номенклатура ilike '%нагреватель%';]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)\nПроблемный SQL запрос: SELECT * FROM Остатки2024 WHERE Номенклатура ilike '%нагреватель%';\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Ошибка при выполнении SQL или сравнении результатов: OperationalError - (sqlite3.OperationalError) no such column: Количество\n[SQL: SELECT * FROM Остатки2024 WHERE Количество = 3;]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)\nПроблемный SQL запрос: SELECT * FROM Остатки2024 WHERE Количество = 3;\n","output_type":"stream"},{"name":"stderr","text":" 21%|██        | 9/43 [01:19<04:34,  8.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 23%|██▎       | 10/43 [01:40<06:28, 11.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 26%|██▌       | 11/43 [02:18<10:36, 19.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 28%|██▊       | 12/43 [02:23<07:56, 15.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 30%|███       | 13/43 [02:40<08:01, 16.05s/it]","output_type":"stream"},{"name":"stdout","text":"Ошибка при выполнении SQL или сравнении результатов: OperationalError - (sqlite3.OperationalError) near \"ilike\": syntax error\n[SQL: SELECT p.Период, p.Регистратор, p.Номерстроки, p.Артикул, p.Номенклатура, p.Документ, p.Код, p.Контрагент, p.СтавкаНДС, p.Организация, p.Заказпокупателя, p.Подразделение, p.Склад, p.Ответственный, p.Номенклатуранабора, p.Проект, p.Количество, p.Сумма, p.ВтчНДС, p.Суммабезскидки, p.Себестоимость, p.СебестоимостьбезНДС, p.Хозяйственнаяоперация FROM Продажи p WHERE p.Номенклатура ilike '%дрожжи%' AND p.Количество > 10;]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)\nПроблемный SQL запрос: SELECT p.Период, p.Регистратор, p.Номерстроки, p.Артикул, p.Номенклатура, p.Документ, p.Код, p.Контрагент, p.СтавкаНДС, p.Организация, p.Заказпокупателя, p.Подразделение, p.Склад, p.Ответственный, p.Номенклатуранабора, p.Проект, p.Количество, p.Сумма, p.ВтчНДС, p.Суммабезскидки, p.Себестоимость, p.СебестоимостьбезНДС, p.Хозяйственнаяоперация FROM Продажи p WHERE p.Номенклатура ilike '%дрожжи%' AND p.Количество > 10;\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 33%|███▎      | 14/43 [02:47<06:17, 13.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 35%|███▍      | 15/43 [03:04<06:44, 14.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 37%|███▋      | 16/43 [03:14<05:49, 12.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 40%|███▉      | 17/43 [03:18<04:31, 10.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 42%|████▏     | 18/43 [03:23<03:39,  8.76s/it]","output_type":"stream"},{"name":"stdout","text":"Ошибка при выполнении SQL или сравнении результатов: OperationalError - (sqlite3.OperationalError) no such column: o.Количество\n[SQL: SELECT * FROM Остатки2024 o WHERE o.Количество = 7 AND o.Сумма > 1000;]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)\nПроблемный SQL запрос: SELECT * FROM Остатки2024 o WHERE o.Количество = 7 AND o.Сумма > 1000;\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 44%|████▍     | 19/43 [03:29<03:07,  7.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 47%|████▋     | 20/43 [03:34<02:43,  7.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 49%|████▉     | 21/43 [03:38<02:17,  6.25s/it]","output_type":"stream"},{"name":"stdout","text":"Ошибка при выполнении SQL или сравнении результатов: OperationalError - (sqlite3.OperationalError) near \"ilike\": syntax error\n[SQL: SELECT * FROM Остатки2024 WHERE Номенклатура ilike '%набор%';]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)\nПроблемный SQL запрос: SELECT * FROM Остатки2024 WHERE Номенклатура ilike '%набор%';\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 51%|█████     | 22/43 [03:44<02:04,  5.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 53%|█████▎    | 23/43 [03:49<01:54,  5.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 56%|█████▌    | 24/43 [04:06<02:53,  9.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 58%|█████▊    | 25/43 [04:11<02:22,  7.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 60%|██████    | 26/43 [04:15<01:55,  6.77s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 63%|██████▎   | 27/43 [04:31<02:31,  9.44s/it]","output_type":"stream"},{"name":"stdout","text":"Ошибка при выполнении SQL или сравнении результатов: OperationalError - (sqlite3.OperationalError) no such table: продажи\n[SQL: SELECT p.период, p.регистратор, p.номерстроки, p.артикул, p.номенклатура, p.документ, p.код, p.контрагент, p.ставкандс, p.организация, p.заказпокупателя, p.подразделение, p.скlad, p.ответственный, p.номенклатуранабора, p.проект, p.количество, p.сумма, p.втчндс, p.суммабезскидки, p.себестоимость, p.себестоимостьбезндс, p.хозяйственнаяоперация FROM продажи p WHERE p.номенклатура LIKE '%Алхимия%';]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)\nПроблемный SQL запрос: SELECT p.период, p.регистратор, p.номерстроки, p.артикул, p.номенклатура, p.документ, p.код, p.контрагент, p.ставкандс, p.организация, p.заказпокупателя, p.подразделение, p.скlad, p.ответственный, p.номенклатуранабора, p.проект, p.количество, p.сумма, p.втчндс, p.суммабезскидки, p.себестоимость, p.себестоимостьбезндс, p.хозяйственнаяоперация FROM продажи p WHERE p.номенклатура LIKE '%Алхимия%';\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 65%|██████▌   | 28/43 [04:43<02:31, 10.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 67%|██████▋   | 29/43 [04:47<01:58,  8.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 70%|██████▉   | 30/43 [04:54<01:44,  8.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 72%|███████▏  | 31/43 [05:12<02:10, 10.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 74%|███████▍  | 32/43 [05:16<01:37,  8.85s/it]","output_type":"stream"},{"name":"stdout","text":"Ошибка при выполнении SQL или сравнении результатов: OperationalError - (sqlite3.OperationalError) no such column: p.СуммаВтчНДС\n[SQL: SELECT * FROM Продажи p WHERE p.СуммаВтчНДС = 144.50;]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)\nПроблемный SQL запрос: SELECT * FROM Продажи p WHERE p.СуммаВтчНДС = 144.50;\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 77%|███████▋  | 33/43 [05:34<01:57, 11.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 79%|███████▉  | 34/43 [05:45<01:43, 11.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 81%|████████▏ | 35/43 [05:49<01:14,  9.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 84%|████████▎ | 36/43 [05:58<01:03,  9.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Ошибка при выполнении SQL или сравнении результатов: OperationalError - (sqlite3.OperationalError) no such column: o.Количество\n[SQL: SELECT * FROM Остатки2024 o WHERE o.Количество > 10;]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)\nПроблемный SQL запрос: SELECT * FROM Остатки2024 o WHERE o.Количество > 10;\n","output_type":"stream"},{"name":"stderr","text":" 86%|████████▌ | 37/43 [06:02<00:46,  7.69s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 88%|████████▊ | 38/43 [06:07<00:33,  6.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Ошибка при выполнении SQL или сравнении результатов: OperationalError - (sqlite3.OperationalError) near \"ilike\": syntax error\n[SQL: SELECT * FROM Остатки2024 o WHERE o.Номенклатура ilike '%дрожжи%';]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)\nПроблемный SQL запрос: SELECT * FROM Остатки2024 o WHERE o.Номенклатура ilike '%дрожжи%';\n","output_type":"stream"},{"name":"stderr","text":" 91%|█████████ | 39/43 [06:12<00:24,  6.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 93%|█████████▎| 40/43 [06:17<00:17,  5.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 95%|█████████▌| 41/43 [06:22<00:11,  5.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 98%|█████████▊| 42/43 [06:26<00:05,  5.25s/it]","output_type":"stream"},{"name":"stdout","text":"Ошибка при выполнении SQL или сравнении результатов: OperationalError - (sqlite3.OperationalError) no such column: p.СуммаНДС\n[SQL: SELECT * FROM Продажи p WHERE p.СуммаНДС = 613.33;]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)\nПроблемный SQL запрос: SELECT * FROM Продажи p WHERE p.СуммаНДС = 613.33;\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Ошибка при выполнении SQL или сравнении результатов: OperationalError - (sqlite3.OperationalError) no such column: o.Склад\n[SQL: SELECT * FROM Остатки2024 o WHERE o.Склад IS NULL;]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)\nПроблемный SQL запрос: SELECT * FROM Остатки2024 o WHERE o.Склад IS NULL;\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 43/43 [06:30<00:00,  9.09s/it]\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"ExcelIO.write_spans(sqlcoder.logger, 'out.xlsx')\nsqlcoder.accuracy(), sqlcoder.TED()","metadata":{"execution":{"iopub.status.busy":"2025-03-25T16:16:07.843644Z","iopub.execute_input":"2025-03-25T16:16:07.844010Z","iopub.status.idle":"2025-03-25T16:16:08.013824Z","shell.execute_reply.started":"2025-03-25T16:16:07.843984Z","shell.execute_reply":"2025-03-25T16:16:08.013129Z"},"trusted":true},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"(0.5878477589280333, 0.6617285258037561)"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"import gc\nimport torch\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T17:48:26.674622Z","iopub.execute_input":"2025-03-24T17:48:26.674902Z","iopub.status.idle":"2025-03-24T17:48:27.170358Z","shell.execute_reply.started":"2025-03-24T17:48:26.674878Z","shell.execute_reply":"2025-03-24T17:48:27.169669Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"#sqlcoder.accuracy()","metadata":{"execution":{"iopub.execute_input":"2025-03-23T12:33:56.208689Z","iopub.status.busy":"2025-03-23T12:33:56.208452Z","iopub.status.idle":"2025-03-23T12:33:56.212205Z","shell.execute_reply":"2025-03-23T12:33:56.211301Z","shell.execute_reply.started":"2025-03-23T12:33:56.208667Z"},"id":"aM5iPZbKfyx1","trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"#sqlcoder.logger","metadata":{"execution":{"iopub.execute_input":"2025-03-23T12:33:56.213214Z","iopub.status.busy":"2025-03-23T12:33:56.213008Z","iopub.status.idle":"2025-03-23T12:33:56.231703Z","shell.execute_reply":"2025-03-23T12:33:56.230996Z","shell.execute_reply.started":"2025-03-23T12:33:56.213194Z"},"id":"dbrujfaxfyx2","trusted":true},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"## DeepSeek 6.7b","metadata":{}},{"cell_type":"code","source":"#deepseek = HuggingFaceModelInference('deepseek-ai/deepseek-coder-6.7b-instruct')\n#deepseek.evaluate(shuffle(queries.as_list())[:10], conn) ","metadata":{"execution":{"iopub.execute_input":"2025-03-23T12:33:56.232744Z","iopub.status.busy":"2025-03-23T12:33:56.232552Z","iopub.status.idle":"2025-03-23T12:33:56.250036Z","shell.execute_reply":"2025-03-23T12:33:56.249379Z","shell.execute_reply.started":"2025-03-23T12:33:56.232726Z"},"trusted":true},"outputs":[],"execution_count":16},{"cell_type":"code","source":"#torch.cuda.empty_cache()","metadata":{"execution":{"iopub.execute_input":"2025-03-23T12:33:56.251145Z","iopub.status.busy":"2025-03-23T12:33:56.250872Z","iopub.status.idle":"2025-03-23T12:33:56.268234Z","shell.execute_reply":"2025-03-23T12:33:56.267418Z","shell.execute_reply.started":"2025-03-23T12:33:56.251113Z"},"trusted":true},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"## 3. Chat2DB 7b","metadata":{"_cell_guid":"d55558bc-4b00-4394-bc4f-c0073a11401d","_uuid":"4ae33630-d334-42a2-8cb6-b598829eff96","collapsed":false,"id":"NeSXnH5efyx2","jupyter":{"outputs_hidden":false},"trusted":true}},{"cell_type":"code","source":"# chat2db = HuggingFaceModelInference('Chat2DB/Chat2DB-SQL-7B')\n# chat2db.evaluate(shuffle(dataset)[:20])","metadata":{"_cell_guid":"6331cae7-1f53-4810-bbac-16746766a115","_uuid":"df11395b-e166-4e60-a8c1-177616885682","execution":{"iopub.execute_input":"2025-03-23T12:33:56.269162Z","iopub.status.busy":"2025-03-23T12:33:56.268895Z","iopub.status.idle":"2025-03-23T12:33:56.284324Z","shell.execute_reply":"2025-03-23T12:33:56.283451Z","shell.execute_reply.started":"2025-03-23T12:33:56.269129Z"},"id":"g2R-FoySfyx2","trusted":true},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# chat2db.accuracy(), chat2db.sql_similarity(), np.mean(chat2db.exec_time)","metadata":{"execution":{"iopub.execute_input":"2025-03-23T12:33:56.285281Z","iopub.status.busy":"2025-03-23T12:33:56.285065Z","iopub.status.idle":"2025-03-23T12:33:56.301509Z","shell.execute_reply":"2025-03-23T12:33:56.300794Z","shell.execute_reply.started":"2025-03-23T12:33:56.285262Z"},"id":"hMmXGF2efyx3","trusted":true},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# dump_inference('Chat2DB-SQL-7B', chat2db.exec_time, chat2db.sql_similarity(), chat2db.accuracy())","metadata":{"_cell_guid":"4fa7c30a-25e6-4896-a7ef-a48677e4a609","_uuid":"9851857f-6885-4d68-b229-64584ef63b7a","collapsed":false,"execution":{"iopub.execute_input":"2025-03-23T12:33:56.302382Z","iopub.status.busy":"2025-03-23T12:33:56.302195Z","iopub.status.idle":"2025-03-23T12:33:56.323577Z","shell.execute_reply":"2025-03-23T12:33:56.322739Z","shell.execute_reply.started":"2025-03-23T12:33:56.302365Z"},"id":"J8Fqx7jtfyx3","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"## 5. DuckDB-NSQL 7b","metadata":{"_cell_guid":"36e6679e-f787-4878-9ece-778d696f902a","_uuid":"fb512d0f-8426-42c4-b47f-8842ea420b28","collapsed":false,"id":"tYwLcup9fyx4","jupyter":{"outputs_hidden":false},"trusted":true}},{"cell_type":"code","source":"# duckdb = HuggingFaceModelInference('motherduckdb/DuckDB-NSQL-7B-v0.1')","metadata":{"_cell_guid":"2d0f45a8-7c98-432e-89ab-59345f8f6888","_uuid":"dab98270-0c45-4157-828c-4fc879b8969a","collapsed":false,"execution":{"iopub.execute_input":"2025-03-23T12:33:56.324854Z","iopub.status.busy":"2025-03-23T12:33:56.324637Z","iopub.status.idle":"2025-03-23T12:33:56.340987Z","shell.execute_reply":"2025-03-23T12:33:56.340206Z","shell.execute_reply.started":"2025-03-23T12:33:56.324835Z"},"id":"Tot4dlxMfyx4","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# duckdb.evaluate(shuffle(dataset)[:30])","metadata":{"execution":{"iopub.execute_input":"2025-03-23T12:33:56.344265Z","iopub.status.busy":"2025-03-23T12:33:56.343985Z","iopub.status.idle":"2025-03-23T12:33:56.357624Z","shell.execute_reply":"2025-03-23T12:33:56.357064Z","shell.execute_reply.started":"2025-03-23T12:33:56.344245Z"},"id":"hPpuGQcSfyx4","trusted":true},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# duckdb.accuracy(), duckdb.sql_similarity(), np.mean(duckdb.exec_time)","metadata":{"execution":{"iopub.execute_input":"2025-03-23T12:33:56.358869Z","iopub.status.busy":"2025-03-23T12:33:56.358591Z","iopub.status.idle":"2025-03-23T12:33:56.379690Z","shell.execute_reply":"2025-03-23T12:33:56.379059Z","shell.execute_reply.started":"2025-03-23T12:33:56.358840Z"},"id":"8Q31HSR_fyx4","trusted":true},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# dump_inference('DuckDB-NSQL-7B-v0.1', duckdb.exec_time, duckdb.sql_similarity(), duckdb.accuracy())","metadata":{"_cell_guid":"d43194c8-3f1f-4412-8b2e-a81bc275fe23","_uuid":"11b3e41a-58b2-4081-9782-366f5920fb0e","collapsed":false,"execution":{"iopub.execute_input":"2025-03-23T12:33:56.380582Z","iopub.status.busy":"2025-03-23T12:33:56.380392Z","iopub.status.idle":"2025-03-23T12:33:56.397363Z","shell.execute_reply":"2025-03-23T12:33:56.396716Z","shell.execute_reply.started":"2025-03-23T12:33:56.380565Z"},"id":"-1cY9b33fyx4","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"## Прочее","metadata":{"_cell_guid":"911306e3-b047-451a-abcf-00dbf37fe1c7","_uuid":"1ef8f63d-9d86-4070-9e67-c10675859a72","collapsed":false,"id":"iyJhh7Srfyx6","jupyter":{"outputs_hidden":false},"trusted":true}},{"cell_type":"code","source":"from numba import cuda\nimport gc\n#cuda.devices.gpus[0].reset()\n#cuda.devices.gpus[1].reset()\n#gc.collect()","metadata":{"_cell_guid":"823de476-d607-4c57-9d9e-90c55ecb6b3b","_uuid":"d845407a-9c1d-459b-8c9c-ec713618828e","collapsed":false,"execution":{"iopub.execute_input":"2025-03-23T12:33:56.398348Z","iopub.status.busy":"2025-03-23T12:33:56.398063Z","iopub.status.idle":"2025-03-23T12:33:58.722280Z","shell.execute_reply":"2025-03-23T12:33:58.721592Z","shell.execute_reply.started":"2025-03-23T12:33:56.398328Z"},"id":"P7KlZTlxfyx6","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":25}]}