{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4bef7992-fd1a-44fd-9da7-96fbbae6e0ec",
    "_uuid": "88b99755-8202-4ddf-a578-eb88c8d5c7ed",
    "collapsed": false,
    "id": "5e2Gc4EPfyxl",
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "# Подготовка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "493f2279-ae45-48f1-a03a-10413c2a4d3b",
    "_uuid": "2b1445fe-507d-4d0b-8633-7e7ea3dcc40c",
    "execution": {
     "iopub.execute_input": "2025-03-23T12:30:36.138081Z",
     "iopub.status.busy": "2025-03-23T12:30:36.137766Z",
     "iopub.status.idle": "2025-03-23T12:30:39.636908Z",
     "shell.execute_reply": "2025-03-23T12:30:39.635904Z",
     "shell.execute_reply.started": "2025-03-23T12:30:36.138049Z"
    },
    "id": "b8V36cmgynSD",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install sentence-transformers -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "56d8808c-d33b-497f-aa3d-19de2f2023c8",
    "_uuid": "590a47b4-6c5b-4716-8c0a-117716a6bba0",
    "execution": {
     "iopub.execute_input": "2025-03-23T12:30:39.638545Z",
     "iopub.status.busy": "2025-03-23T12:30:39.638314Z",
     "iopub.status.idle": "2025-03-23T12:31:14.868739Z",
     "shell.execute_reply": "2025-03-23T12:31:14.867730Z",
     "shell.execute_reply.started": "2025-03-23T12:30:39.638518Z"
    },
    "id": "YQ3a_27dyOco",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sqlglot import parse_one\n",
    "from sqlglot.diff import ChangeDistiller\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.utils import shuffle\n",
    "from sqlalchemy import Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='alert alert-info'>spans.py</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T12:31:14.870273Z",
     "iopub.status.busy": "2025-03-23T12:31:14.869675Z",
     "iopub.status.idle": "2025-03-23T12:31:14.875889Z",
     "shell.execute_reply": "2025-03-23T12:31:14.875023Z",
     "shell.execute_reply.started": "2025-03-23T12:31:14.870236Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from abc import ABC\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Span(ABC):\n",
    "    pass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ExtendedSqlSpan(Span):\n",
    "    NL : str\n",
    "    sql_gold : str\n",
    "    sql_pred : str\n",
    "    df_soft : int\n",
    "    df_flexible : int\n",
    "    df_gold_IN_df_pred : bool\n",
    "    df_pred_IN_df_gold : bool\n",
    "    df_gold_columns : list[str]\n",
    "    df_pred_columns : list[str]\n",
    "    TED : int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='alert alert-info'>general.py</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T12:31:14.877307Z",
     "iopub.status.busy": "2025-03-23T12:31:14.877003Z",
     "iopub.status.idle": "2025-03-23T12:31:14.990484Z",
     "shell.execute_reply": "2025-03-23T12:31:14.989772Z",
     "shell.execute_reply.started": "2025-03-23T12:31:14.877265Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from abc import ABC\n",
    "import numpy as np\n",
    "from sentence_transformers import util\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "from sqlglot import exp\n",
    "import sqlglot.optimizer\n",
    "import re\n",
    "\n",
    "def find_similar_sentences(sentence_model, target_sentence : str, sentences : list[str], count : int = 3):\n",
    "    \"\"\"\n",
    "    Функция поиска похожих по смыслу предложений из набора `sentences` для указанного предложения `target_sentence`\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sentence_model : Any\n",
    "        Модель, позволяющая векторизовать текст\n",
    "    target_sentence: str\n",
    "        Предложение, для которого нужно найти похожие по смыслу предложения\n",
    "    sentences : List[str]\n",
    "        Набор предложений\n",
    "    count : int\n",
    "        Количество ожидаемых предложений\n",
    "    \"\"\"\n",
    "\n",
    "    emb_target = sentence_model.encode(target_sentence)\n",
    "\n",
    "    sims = []\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        emb_sentence = sentence_model.encode(sentence)\n",
    "        sim = util.pytorch_cos_sim(emb_sentence, emb_target)\n",
    "        sims.append([i, np.float16(sim.squeeze())])\n",
    "\n",
    "    nearest = sorted(sims, key=lambda pair : pair[1], reverse=True)\n",
    "    similar_questions = [sentences[pair[0]] for pair in nearest if pair[1] != 1.0][:count]\n",
    "    return similar_questions\n",
    "\n",
    "\n",
    "def find_sql(text : str, start_keyword='SELECT'):\n",
    "    \"\"\"\n",
    "    Функция, которая ищет в строке `text` первое вхождение самого длинного, правильного SQL запроса\n",
    "    \"\"\"\n",
    "\n",
    "    matches = re.search(f'({start_keyword}).*', text, flags=re.IGNORECASE)\n",
    "    if not matches:\n",
    "        return ''\n",
    "\n",
    "    begin_sql = matches.group()\n",
    "    splitted = begin_sql.split()\n",
    "\n",
    "    maybe_sql = ''\n",
    "    last_success_pos = 0\n",
    "    for i, word in enumerate(splitted):\n",
    "        maybe_sql += f' {word}'\n",
    "        try:\n",
    "            sqlglot.transpile(maybe_sql)\n",
    "            last_success_pos = i\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    found_sql = ' '.join(splitted[:last_success_pos + 1])\n",
    "    return found_sql\n",
    "\n",
    "\n",
    "def table_similarity(dataframe1 : pd.DataFrame, dataframe2 : pd.DataFrame, mode : str) -> int:\n",
    "    \"\"\"\n",
    "    Функция сравнения двух таблиц\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe1 : pd.DataFrame\n",
    "        Первая таблица\n",
    "    dataframe2 : pd.DataFrame\n",
    "        Вторая таблица\n",
    "    mode : str\n",
    "        Режим сравнения. Допустимы режимы soft, strict, flexible\n",
    "    \"\"\"\n",
    "\n",
    "    # if dataframe1.columns.shape != dataframe2.columns.shape:\n",
    "    #     return False\n",
    "    # if not (dataframe1.columns == dataframe2.columns).all():\n",
    "    #     return False\n",
    "    \n",
    "    match mode:\n",
    "        case 'soft':\n",
    "            return int(dataframe1.sort_index().equals(dataframe2.sort_index()))\n",
    "        case 'strict':\n",
    "            return int(dataframe1.equals(dataframe2))\n",
    "        case 'flexible':\n",
    "            hash_1 = set(pd.util.hash_pandas_object(dataframe1, index=False))\n",
    "            hash_2 = set(pd.util.hash_pandas_object(dataframe2, index=False))\n",
    "            intersection = hash_1 & hash_2\n",
    "            union = hash_1 | hash_2\n",
    "\n",
    "            return len(intersection) / len(union) if len(union) != 0 else 1\n",
    "        case _:\n",
    "            raise Exception('Incorrect mode value')\n",
    "     \n",
    "\n",
    "def unzip_file(path, path_to):\n",
    "    with zipfile.ZipFile(path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(path_to)\n",
    "\n",
    "\n",
    "def schema_parse(sql : str, structure_dict : dict):\n",
    "    \"\"\"\n",
    "    Функция, вытягивающая все названия таблиц и столбцов, которые упомянуты в запросе `sql`\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sql : str\n",
    "        SQL запрос\n",
    "    table_structure : List[dict]\n",
    "        Структура таблицы, которая может быть получена при помощи функции `structure_from_connection`\n",
    "    \"\"\"\n",
    "\n",
    "    optimized_sql = sqlglot.optimizer.optimize(\n",
    "        sqlglot.parse_one(sql),\n",
    "        schema=structure_dict\n",
    "    )\n",
    "\n",
    "    buckets = {table.name : set([]) for table in optimized_sql.find_all(exp.Table)}\n",
    "    for column in optimized_sql.find_all(exp.Column):\n",
    "        table_of_col = column.table\n",
    "        buckets[table_of_col].add(column.name)\n",
    "\n",
    "    as_default = []\n",
    "    for k, v in buckets.items():\n",
    "        as_default.append({'table_name' : k, 'columns' : list(v)})\n",
    "\n",
    "    return as_default\n",
    "\n",
    "\n",
    "class ExcelIO(object):\n",
    "    @staticmethod\n",
    "    def write_spans(spans : list[Span], path : str):\n",
    "        asdict = [span.__dict__ for span in spans]\n",
    "        df = pd.DataFrame(asdict)\n",
    "        df.to_excel(excel_writer=path, index=False)\n",
    "\n",
    "    @staticmethod\n",
    "    def read_excel(path : str):\n",
    "        df = pd.read_excel(path)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='alert alert-info'>dataset.py</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T12:31:14.991662Z",
     "iopub.status.busy": "2025-03-23T12:31:14.991385Z",
     "iopub.status.idle": "2025-03-23T12:31:15.002438Z",
     "shell.execute_reply": "2025-03-23T12:31:15.001668Z",
     "shell.execute_reply.started": "2025-03-23T12:31:14.991628Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "from sqlalchemy import text, Connection, inspect\n",
    "\n",
    "class IterableDataFrame:\n",
    "    \"\"\"\n",
    "    Класс, позволяющий итерироваться в таблице типа `pd.DataFrame`\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df : pd.DataFrame):\n",
    "        self.df = df\n",
    "        self.__series = {}\n",
    "        for idx in self.df.index:\n",
    "            sample = {\n",
    "                column : self.df[self.df.index == idx][column][idx] for column in self.df.keys()\n",
    "            }\n",
    "            self.__series[idx] = sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __as_list(self):\n",
    "        return list(self.__series.values())\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return iter(self.__as_list())\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.__as_list()[index]\n",
    "    \n",
    "    def at_index(self, index):\n",
    "        return self.__series[index]\n",
    "\n",
    "\n",
    "def tables_from_connection(conn : Connection):\n",
    "    \"\"\"\n",
    "    Функция, возвращающая список названий всех таблиц для данного соединения `conn`\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    conn : sqlalchemy.Connection\n",
    "        Соединение с базой данных\n",
    "    \"\"\"\n",
    "\n",
    "    master = pd.DataFrame(conn.execute(text('SELECT * FROM sqlite_master')).fetchall())\n",
    "    tables = list(master[master['type'] == 'table']['name'])\n",
    "    return tables\n",
    "\n",
    "\n",
    "def structure_from_connection(conn : Connection):\n",
    "    \"\"\"\n",
    "    Функция, возвращающая список словарей вида {table_name, columns}, где table_name - str, а columns - List[str]\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    conn : sqlalchemy.Connection\n",
    "        Соединение с базой данных\n",
    "    \"\"\"\n",
    "\n",
    "    tables = tables_from_connection(conn)\n",
    "    structure = []\n",
    "    for table in tables:\n",
    "        columns = pd.DataFrame(conn.execute(text(f'SELECT * FROM \"{table}\"')).fetchall()).columns.to_list()\n",
    "        structure.append(\n",
    "            {\n",
    "                'table_name' : table,\n",
    "                'columns' : columns\n",
    "            })\n",
    "        \n",
    "    return structure\n",
    "\n",
    "\n",
    "def structure_from_connection_dict(conn : Connection):\n",
    "    \"\"\"\n",
    "    Функция, возвращающая словарь словарей вида {\"Table\" : {\"Col\" : \"INT\", ...}}\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    conn : sqlalchemy.Connection\n",
    "        Соединение с базой данных\n",
    "    \"\"\"\n",
    "\n",
    "    tables = tables_from_connection(conn)\n",
    "    structure = {}\n",
    "    for table in tables:\n",
    "        columns = inspect(conn).get_columns(table)\n",
    "        columns_meta = {column['name'] : column['type'] for column in columns}\n",
    "        structure[table] = columns_meta\n",
    "\n",
    "    return structure\n",
    "\n",
    "\n",
    "def prepare_column_names(conn : Connection):\n",
    "    \"\"\"\n",
    "    Функция, обрабатывающая базу данных из соединения `conn`. Функция переименовывает названия всех таблиц и их столбцов, \n",
    "    которые содержат whitespace и punctuation символы. Возвращает True, если переименовывание прошло успешно\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    conn : sqlalchemy.Connection\n",
    "        Соединение с базой данных\n",
    "    \"\"\"\n",
    "    \n",
    "    structure = structure_from_connection(conn)\n",
    "    for table in structure:\n",
    "        for column in table['columns']:\n",
    "            new_name = str.lower(''.join([char for char in column if str.isalnum(char)]))\n",
    "            if new_name != column:\n",
    "                conn.execute(text(\n",
    "                    f'''ALTER TABLE \"{table['table_name']}\" RENAME COLUMN \"{column}\" TO \"{new_name}\"'''\n",
    "                ))\n",
    "\n",
    "        new_table_name = str.lower(''.join([char for char in table['table_name'] if str.isalnum(char)]))\n",
    "        if new_table_name != table['table_name']:\n",
    "            conn.execute(text(f'''ALTER TABLE \"{table['table_name']}\" RENAME TO \"{new_table_name}\"'''))\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='alert alert-info'>prompting.py</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T12:31:15.005168Z",
     "iopub.status.busy": "2025-03-23T12:31:15.004836Z",
     "iopub.status.idle": "2025-03-23T12:31:15.029365Z",
     "shell.execute_reply": "2025-03-23T12:31:15.028636Z",
     "shell.execute_reply.started": "2025-03-23T12:31:15.005133Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlalchemy\n",
    "\n",
    "\n",
    "class PromptBuilder:\n",
    "    \"\"\"\n",
    "    Класс, отвечающий за создание промпта на основе указанных фичей\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.__prompt = ''\n",
    "        self.schema_linking = False\n",
    "\n",
    "\n",
    "    def add_schema_linking(self, table_structure=None):\n",
    "        \"\"\"\n",
    "        Метод, добавляющий режим использования фичи Schema Linking. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        table_structure : Any\n",
    "            Структура таблицы, которая может быть получена с помощью функции `structure_from_connection`\n",
    "        \"\"\"\n",
    "\n",
    "        self.table_structure = table_structure\n",
    "        self.schema_linking = True\n",
    "        return self\n",
    "\n",
    "\n",
    "    def add_few_shot(self, queries, target_question : str, sentence_model):\n",
    "        \"\"\"\n",
    "        Метод, отвечающий за добавление фичи Few-Shot в промпт\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        sentence_model : Any\n",
    "            Модель, позволяющая векторизовать текст\n",
    "        target_question : str\n",
    "            Вопрос, для которого нужно найти похожие по смыслу вопросы\n",
    "        queries : Any\n",
    "            Набор вопросов и запросов, среди которых нужно найти ближайшие по смыслу вопросы. Объект должен являться матрицей Nx2\n",
    "        \"\"\"\n",
    "\n",
    "        questions = [sample['question'] for sample in queries]\n",
    "\n",
    "        input_examples = []\n",
    "        similar = find_similar_sentences(sentence_model, target_question, questions, count=3)\n",
    "        for sample in queries:\n",
    "            curr_qs = sample['question']\n",
    "            if curr_qs in similar:\n",
    "                input_examples.append([curr_qs, sample['query']])\n",
    "\n",
    "        few_shot_template = ''\n",
    "        for ex in input_examples:\n",
    "            few_shot_template += f'Q: {ex[0]}\\n'\n",
    "            few_shot_template += f'A: {ex[1]}\\n'\n",
    "\n",
    "        self.__prompt += few_shot_template + '\\n'\n",
    "        return self\n",
    "    \n",
    "\n",
    "    def add_schema_template(self, db_conn : sqlalchemy.Connection):\n",
    "        \"\"\"\n",
    "        Метод, отвечающий за добавление фичи Schema Template в промпт\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        db_conn : sqlalchemy.Connection\n",
    "            Соединение с базой данных\n",
    "        \"\"\"\n",
    "\n",
    "        if self.schema_linking:\n",
    "            structure = self.table_structure\n",
    "        else:\n",
    "            structure = structure_from_connection(db_conn)\n",
    "\n",
    "        schema_template = ''\n",
    "        for table in structure:\n",
    "            schema_template += f\"{table['table_name']}({', '.join(table['columns'])});\\n\"\n",
    "\n",
    "        self.__prompt += schema_template + '\\n'\n",
    "        return self\n",
    "\n",
    "\n",
    "    def add_cell_value_referencing(self, db_conn : sqlalchemy.Connection, count=1):\n",
    "        \"\"\"\n",
    "        Метод, отвечающий за добавление фичи Cell Value Referencing в промпт\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        db_conn : sqlalchemy.Connection\n",
    "            Соединение с базой данных\n",
    "        count : int\n",
    "            Ожидаемое количество примеров для добавления. По умолчанию равно 1\n",
    "        \"\"\"\n",
    "\n",
    "        if self.schema_linking:\n",
    "            tables = [table['table_name'] for table in self.table_structure]\n",
    "        else:\n",
    "            tables = tables_from_connection(db_conn)\n",
    "\n",
    "        data_information = []\n",
    "        for table in tables:\n",
    "            if self.schema_linking:\n",
    "                instance = [bucket for bucket in self.table_structure if bucket['table_name'] == table][0]\n",
    "                pd_table = pd.read_sql(f'SELECT * FROM {table}', db_conn)[instance['columns']]\n",
    "            else:\n",
    "                pd_table = pd.read_sql(f'SELECT * FROM {table}', db_conn)\n",
    "            \n",
    "            indexes = np.random.randint(0, pd_table.shape[0], size=count)\n",
    "            series = [pd_table[pd_table.index == idx].to_numpy() for idx in indexes]\n",
    "\n",
    "            data_information.append({\n",
    "                'table_name' : table,\n",
    "                'examples' : [f\"[{', '.join(map(str,list(ser.reshape(ser.shape[1]))))}]\" for ser in series]\n",
    "            })\n",
    "\n",
    "        value_template = ''\n",
    "        for data in data_information:\n",
    "            value_template += f\"{data['table_name']}({', '.join(data['examples'])});\\n\"\n",
    "\n",
    "        self.__prompt += value_template + '\\n'\n",
    "        return self\n",
    "\n",
    "\n",
    "    def add_message(self, message : str):\n",
    "        self.__prompt += message + '\\n'\n",
    "        return self\n",
    "\n",
    "\n",
    "    def build_prompt(self):\n",
    "        return self.__prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='alert alert-info'>models-evaluation.ipynb</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T12:31:15.031489Z",
     "iopub.status.busy": "2025-03-23T12:31:15.031214Z",
     "iopub.status.idle": "2025-03-23T12:31:15.111278Z",
     "shell.execute_reply": "2025-03-23T12:31:15.110537Z",
     "shell.execute_reply.started": "2025-03-23T12:31:15.031468Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:////kaggle/input/main-database/main_database.sqlite', echo=False)\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T12:31:15.112293Z",
     "iopub.status.busy": "2025-03-23T12:31:15.112075Z",
     "iopub.status.idle": "2025-03-23T12:31:17.084455Z",
     "shell.execute_reply": "2025-03-23T12:31:17.083742Z",
     "shell.execute_reply.started": "2025-03-23T12:31:15.112274Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "prepare_column_names(conn) # Устраняет пробелы в названии столбцов\n",
    "queries = IterableDataFrame(pd.read_excel('/kaggle/input/main-database/NLSQL.xlsx'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "60baf893-838f-4564-b751-92fdb1ab2a4d",
    "_uuid": "ea5468d0-d708-4c03-aac9-6cca9e60a383",
    "collapsed": false,
    "id": "bbFNaY5A4KVs",
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "# Препроцессинг промпта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T12:31:17.085709Z",
     "iopub.status.busy": "2025-03-23T12:31:17.085209Z",
     "iopub.status.idle": "2025-03-23T12:31:20.596175Z",
     "shell.execute_reply": "2025-03-23T12:31:20.595224Z",
     "shell.execute_reply.started": "2025-03-23T12:31:17.085684Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sentence_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "badd3dde-3fb0-433b-9a81-50d83886e96e",
    "_uuid": "8e31e90d-f714-43c9-b231-be1788cbcdc6",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-03-23T12:31:20.597603Z",
     "iopub.status.busy": "2025-03-23T12:31:20.597335Z",
     "iopub.status.idle": "2025-03-23T12:31:20.611310Z",
     "shell.execute_reply": "2025-03-23T12:31:20.610476Z",
     "shell.execute_reply.started": "2025-03-23T12:31:20.597572Z"
    },
    "id": "HBRQjrXdfyxx",
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class HuggingFaceModelInference:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.evaluated = False\n",
    "        self.is_downloaded = False\n",
    "\n",
    "\n",
    "    def __load_model(self):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.path, trust_remote_code=True)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "                    self.path,\n",
    "                    torch_dtype=torch.float16,\n",
    "                    device_map=\"auto\",\n",
    "                    max_memory={0: \"10GiB\", 1: \"10GiB\"},  \n",
    "                    offload_folder=\"./offload\", \n",
    "                    trust_remote_code=True\n",
    "                    )\n",
    "\n",
    "    def __inference(self, prompt):\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "        with torch.inference_mode():  \n",
    "            inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.model.device) \n",
    "            generate_ids = self.model.generate(\n",
    "                            **inputs,\n",
    "                            max_length=2048,\n",
    "                            num_return_sequences=1,\n",
    "                            temperature=0.2, \n",
    "                            top_p=0.95,\n",
    "                            do_sample=True,\n",
    "                            use_cache=True \n",
    "                            )\n",
    "    \n",
    "            output = self.tokenizer.decode(\n",
    "                    generate_ids[0, inputs.input_ids.shape[1]:],\n",
    "                    skip_special_tokens=True\n",
    "                    )\n",
    "            \n",
    "        return output\n",
    "    \n",
    "\n",
    "    def evaluate(self, queries : IterableDataFrame, connection : Connection):\n",
    "        if not self.is_downloaded:\n",
    "            self.__load_model()\n",
    "            self.is_downloaded = True\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        logger : list[ExtendedSqlSpan] = []\n",
    "        summary = 0\n",
    "        for query in tqdm(queries):\n",
    "            question = query['question']\n",
    "            gold_sql = query['query']\n",
    "\n",
    "            prompt = PromptBuilder()\\\n",
    "                .add_message('### You are an expert SQL developer with deep knowledge of database optimization, correct syntax, and efficient query design. Your task is to generate accurate, performant SQL queries based on the provided input.')\\\n",
    "                .add_message(\"### Table schema:\")\\\n",
    "                .add_schema_template(conn)\\\n",
    "                .add_message(\"### Examples of data\")\\\n",
    "                .add_cell_value_referencing(conn, count=1)\\\n",
    "                .add_message(f\"### Your task: {question}\")\\\n",
    "                .build_prompt()\n",
    "            \n",
    "\n",
    "            output = self.__inference(prompt)\n",
    "            pred_sql = find_sql(output, start_keyword='SELECT')\n",
    "            \n",
    "            df_gold = pd.read_sql(gold_sql, connection)\n",
    "            try:\n",
    "                df_pred = pd.read_sql(pred_sql, connection)\n",
    "                \n",
    "                span_df_soft        = table_similarity(df_pred, df_gold, mode='soft')\n",
    "                span_df_flexible    = table_similarity(df_pred, df_gold, mode='flexible')\n",
    "                span_gold_IN_pred   = False #\n",
    "                span_pred_IN_gold   = False # Добавить проверку\n",
    "                span_pred_columns   = df_pred.columns.to_list()\n",
    "                span_ted            = self.__ted_compare(pred_sql, gold_sql)  \n",
    "            except:\n",
    "                # По определению полагаем\n",
    "                span_df_soft        = .0\n",
    "                span_df_flexible    = .0\n",
    "                span_gold_IN_pred   = False\n",
    "                span_pred_IN_gold   = False\n",
    "                span_pred_columns   = []\n",
    "                span_ted            = .0\n",
    "\n",
    "\n",
    "            sql_span = ExtendedSqlSpan(\n",
    "                    NL                 =question,\n",
    "                    sql_gold           =gold_sql,\n",
    "                    sql_pred           =pred_sql,\n",
    "                    df_soft            =span_df_soft,\n",
    "                    df_flexible        =span_df_flexible,\n",
    "                    df_pred_IN_df_gold =span_pred_IN_gold,\n",
    "                    df_gold_IN_df_pred =span_gold_IN_pred,\n",
    "                    df_gold_columns    =df_gold.columns.to_list(),\n",
    "                    df_pred_columns    =span_pred_columns,\n",
    "                    TED                =span_ted\n",
    "                )\n",
    "\n",
    "            summary += span_df_flexible\n",
    "            logger.append(sql_span)\n",
    "        \n",
    "        self.summary = summary\n",
    "        self.queries_count = len(queries)\n",
    "        self.logger = logger\n",
    "        self.evaluated = True\n",
    "\n",
    "\n",
    "    def accuracy(self):\n",
    "        \"\"\"\n",
    "        Значение метрики Accuracy для последнего запуска модели\n",
    "        \"\"\"\n",
    "\n",
    "        if not self.evaluated:\n",
    "            raise Exception('Model was not been evaluated')\n",
    "        \n",
    "        return self.summary / self.queries_count\n",
    "    \n",
    "\n",
    "    def __ted_compare(self, sql1 : str, sql2 : str):\n",
    "        \"\"\"\n",
    "        Компоратор для двух деревьев\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            exp1 = parse_one(sql1)\n",
    "            exp2 = parse_one(sql2)\n",
    "        except:\n",
    "            return .0\n",
    "\n",
    "        distiller = ChangeDistiller()\n",
    "        _ = distiller.diff(exp1, exp2)\n",
    "        return distiller._dice_coefficient(exp1, exp2)\n",
    "\n",
    "\n",
    "    def TED(self):\n",
    "        \"\"\"\n",
    "        Значение метрики Tree Edit Distance для последнего запуска модели\n",
    "        \"\"\"\n",
    "\n",
    "        if not self.evaluated:\n",
    "            raise Exception('Model was not been evaluated')\n",
    "        \n",
    "        summary = 0\n",
    "        for span in self.logger:\n",
    "            summary += self.__ted_compare(span.sql_pred, span.sql_gold)\n",
    "\n",
    "        return summary / self.queries_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "59e279e6-9308-465d-aad6-7fa856d74ad2",
    "_uuid": "f9b0239a-cfac-4e3e-8b90-0e9d6ee06664",
    "collapsed": false,
    "id": "OXTC7kCufyx0",
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## 1. SQLCoder 7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "27adee9a-3a22-4869-a3a6-a5d9b84fdafd",
    "_uuid": "02b26db7-9f82-4958-bd91-e60dc1e4c969",
    "execution": {
     "iopub.execute_input": "2025-03-23T12:36:08.474872Z",
     "iopub.status.busy": "2025-03-23T12:36:08.474536Z",
     "iopub.status.idle": "2025-03-23T12:41:17.530307Z",
     "shell.execute_reply": "2025-03-23T12:41:17.529564Z",
     "shell.execute_reply.started": "2025-03-23T12:36:08.474849Z"
    },
    "id": "vCQKMr7_fyx0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sqlcoder = HuggingFaceModelInference('defog/sqlcoder-7b-2')\n",
    "sqlcoder.evaluate(shuffle(queries), conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T12:41:17.531543Z",
     "iopub.status.busy": "2025-03-23T12:41:17.531325Z",
     "iopub.status.idle": "2025-03-23T12:41:17.650181Z",
     "shell.execute_reply": "2025-03-23T12:41:17.649314Z",
     "shell.execute_reply.started": "2025-03-23T12:41:17.531519Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.727111233685645, 0.7697925963013272)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ExcelIO.write_spans(sqlcoder.logger, 'out.xlsx')\n",
    "sqlcoder.accuracy(), sqlcoder.TED()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T12:33:56.208689Z",
     "iopub.status.busy": "2025-03-23T12:33:56.208452Z",
     "iopub.status.idle": "2025-03-23T12:33:56.212205Z",
     "shell.execute_reply": "2025-03-23T12:33:56.211301Z",
     "shell.execute_reply.started": "2025-03-23T12:33:56.208667Z"
    },
    "id": "aM5iPZbKfyx1",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#sqlcoder.accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T12:33:56.213214Z",
     "iopub.status.busy": "2025-03-23T12:33:56.213008Z",
     "iopub.status.idle": "2025-03-23T12:33:56.231703Z",
     "shell.execute_reply": "2025-03-23T12:33:56.230996Z",
     "shell.execute_reply.started": "2025-03-23T12:33:56.213194Z"
    },
    "id": "dbrujfaxfyx2",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#sqlcoder.logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepSeek 6.7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T12:33:56.232744Z",
     "iopub.status.busy": "2025-03-23T12:33:56.232552Z",
     "iopub.status.idle": "2025-03-23T12:33:56.250036Z",
     "shell.execute_reply": "2025-03-23T12:33:56.249379Z",
     "shell.execute_reply.started": "2025-03-23T12:33:56.232726Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#deepseek = HuggingFaceModelInference('deepseek-ai/deepseek-coder-6.7b-instruct')\n",
    "#deepseek.evaluate(shuffle(queries.as_list())[:10], conn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T12:33:56.251145Z",
     "iopub.status.busy": "2025-03-23T12:33:56.250872Z",
     "iopub.status.idle": "2025-03-23T12:33:56.268234Z",
     "shell.execute_reply": "2025-03-23T12:33:56.267418Z",
     "shell.execute_reply.started": "2025-03-23T12:33:56.251113Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d55558bc-4b00-4394-bc4f-c0073a11401d",
    "_uuid": "4ae33630-d334-42a2-8cb6-b598829eff96",
    "collapsed": false,
    "id": "NeSXnH5efyx2",
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## 3. Chat2DB 7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "6331cae7-1f53-4810-bbac-16746766a115",
    "_uuid": "df11395b-e166-4e60-a8c1-177616885682",
    "execution": {
     "iopub.execute_input": "2025-03-23T12:33:56.269162Z",
     "iopub.status.busy": "2025-03-23T12:33:56.268895Z",
     "iopub.status.idle": "2025-03-23T12:33:56.284324Z",
     "shell.execute_reply": "2025-03-23T12:33:56.283451Z",
     "shell.execute_reply.started": "2025-03-23T12:33:56.269129Z"
    },
    "id": "g2R-FoySfyx2",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# chat2db = HuggingFaceModelInference('Chat2DB/Chat2DB-SQL-7B')\n",
    "# chat2db.evaluate(shuffle(dataset)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T12:33:56.285281Z",
     "iopub.status.busy": "2025-03-23T12:33:56.285065Z",
     "iopub.status.idle": "2025-03-23T12:33:56.301509Z",
     "shell.execute_reply": "2025-03-23T12:33:56.300794Z",
     "shell.execute_reply.started": "2025-03-23T12:33:56.285262Z"
    },
    "id": "hMmXGF2efyx3",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# chat2db.accuracy(), chat2db.sql_similarity(), np.mean(chat2db.exec_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "4fa7c30a-25e6-4896-a7ef-a48677e4a609",
    "_uuid": "9851857f-6885-4d68-b229-64584ef63b7a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-03-23T12:33:56.302382Z",
     "iopub.status.busy": "2025-03-23T12:33:56.302195Z",
     "iopub.status.idle": "2025-03-23T12:33:56.323577Z",
     "shell.execute_reply": "2025-03-23T12:33:56.322739Z",
     "shell.execute_reply.started": "2025-03-23T12:33:56.302365Z"
    },
    "id": "J8Fqx7jtfyx3",
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# dump_inference('Chat2DB-SQL-7B', chat2db.exec_time, chat2db.sql_similarity(), chat2db.accuracy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "36e6679e-f787-4878-9ece-778d696f902a",
    "_uuid": "fb512d0f-8426-42c4-b47f-8842ea420b28",
    "collapsed": false,
    "id": "tYwLcup9fyx4",
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## 5. DuckDB-NSQL 7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "2d0f45a8-7c98-432e-89ab-59345f8f6888",
    "_uuid": "dab98270-0c45-4157-828c-4fc879b8969a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-03-23T12:33:56.324854Z",
     "iopub.status.busy": "2025-03-23T12:33:56.324637Z",
     "iopub.status.idle": "2025-03-23T12:33:56.340987Z",
     "shell.execute_reply": "2025-03-23T12:33:56.340206Z",
     "shell.execute_reply.started": "2025-03-23T12:33:56.324835Z"
    },
    "id": "Tot4dlxMfyx4",
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# duckdb = HuggingFaceModelInference('motherduckdb/DuckDB-NSQL-7B-v0.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T12:33:56.344265Z",
     "iopub.status.busy": "2025-03-23T12:33:56.343985Z",
     "iopub.status.idle": "2025-03-23T12:33:56.357624Z",
     "shell.execute_reply": "2025-03-23T12:33:56.357064Z",
     "shell.execute_reply.started": "2025-03-23T12:33:56.344245Z"
    },
    "id": "hPpuGQcSfyx4",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# duckdb.evaluate(shuffle(dataset)[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T12:33:56.358869Z",
     "iopub.status.busy": "2025-03-23T12:33:56.358591Z",
     "iopub.status.idle": "2025-03-23T12:33:56.379690Z",
     "shell.execute_reply": "2025-03-23T12:33:56.379059Z",
     "shell.execute_reply.started": "2025-03-23T12:33:56.358840Z"
    },
    "id": "8Q31HSR_fyx4",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# duckdb.accuracy(), duckdb.sql_similarity(), np.mean(duckdb.exec_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "d43194c8-3f1f-4412-8b2e-a81bc275fe23",
    "_uuid": "11b3e41a-58b2-4081-9782-366f5920fb0e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-03-23T12:33:56.380582Z",
     "iopub.status.busy": "2025-03-23T12:33:56.380392Z",
     "iopub.status.idle": "2025-03-23T12:33:56.397363Z",
     "shell.execute_reply": "2025-03-23T12:33:56.396716Z",
     "shell.execute_reply.started": "2025-03-23T12:33:56.380565Z"
    },
    "id": "-1cY9b33fyx4",
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# dump_inference('DuckDB-NSQL-7B-v0.1', duckdb.exec_time, duckdb.sql_similarity(), duckdb.accuracy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "911306e3-b047-451a-abcf-00dbf37fe1c7",
    "_uuid": "1ef8f63d-9d86-4070-9e67-c10675859a72",
    "collapsed": false,
    "id": "iyJhh7Srfyx6",
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## Прочее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "823de476-d607-4c57-9d9e-90c55ecb6b3b",
    "_uuid": "d845407a-9c1d-459b-8c9c-ec713618828e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-03-23T12:33:56.398348Z",
     "iopub.status.busy": "2025-03-23T12:33:56.398063Z",
     "iopub.status.idle": "2025-03-23T12:33:58.722280Z",
     "shell.execute_reply": "2025-03-23T12:33:58.721592Z",
     "shell.execute_reply.started": "2025-03-23T12:33:56.398328Z"
    },
    "id": "P7KlZTlxfyx6",
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "import gc\n",
    "#cuda.devices.gpus[0].reset()\n",
    "#cuda.devices.gpus[1].reset()\n",
    "#gc.collect()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6946224,
     "sourceId": 11136692,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
