{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"gpuType":"T4","provenance":[]},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10927604,"sourceType":"datasetVersion","datasetId":6794143}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Подготовка датасета","metadata":{"_cell_guid":"4bef7992-fd1a-44fd-9da7-96fbbae6e0ec","_uuid":"88b99755-8202-4ddf-a578-eb88c8d5c7ed","collapsed":false,"id":"5e2Gc4EPfyxl","jupyter":{"outputs_hidden":false},"trusted":true}},{"cell_type":"code","source":"!pip install json5 gdown sentence-transformers zss -q","metadata":{"_cell_guid":"493f2279-ae45-48f1-a03a-10413c2a4d3b","_uuid":"2b1445fe-507d-4d0b-8633-7e7ea3dcc40c","id":"b8V36cmgynSD","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json5\nfrom tqdm import tqdm\nimport pandas as pd\n# from unittest import TestCase, TextTestRunner, defaultTestLoader\nimport re, time\nfrom sentence_transformers import SentenceTransformer\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport numpy as np\nimport torch\nfrom sqlalchemy import create_engine\nfrom sklearn.utils import shuffle\nfrom sqlalchemy import text, Connection\nimport matplotlib.pyplot as plt","metadata":{"_cell_guid":"56d8808c-d33b-497f-aa3d-19de2f2023c8","_uuid":"590a47b4-6c5b-4716-8c0a-117716a6bba0","id":"YQ3a_27dyOco","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom sentence_transformers import util\nimport pandas as pd\nimport zipfile\nimport sqlparse\n\n\n\ndef find_similar_sentences(sentence_model, target_sentence : str, sentences : list[str], count : int = 3):\n    emb_target = sentence_model.encode(target_sentence)\n\n    sims = []\n    for i, sentence in enumerate(sentences):\n        emb_sentence = sentence_model.encode(sentence)\n        sim = util.pytorch_cos_sim(emb_sentence, emb_target)\n        sims.append([i, np.float16(sim.squeeze())])\n\n    nearest = sorted(sims, key=lambda pair : pair[1], reverse=True)\n    similar_questions = [sentences[pair[0]] for pair in nearest if pair[1] != 1.0][:count]\n    return similar_questions\n\n\ndef table_similarity(dataframe1 : pd.DataFrame, dataframe2 : pd.DataFrame, mode : str) -> int:\n    # if dataframe1.columns.shape != dataframe2.columns.shape:\n    #     return False\n    # if not (dataframe1.columns == dataframe2.columns).all():\n    #     return False\n    \n    match mode:\n        case 'soft':\n            return int(dataframe1.sort_index().equals(dataframe2.sort_index()))\n        case 'strict':\n            return int(dataframe1.equals(dataframe2))\n        case 'flexible':\n            hash_1 = set(pd.util.hash_pandas_object(dataframe1, index=False))\n            hash_2 = set(pd.util.hash_pandas_object(dataframe2, index=False))\n            intersection = hash_1 & hash_2\n            union = hash_1 | hash_2\n\n            return len(intersection) / len(union) if len(union) != 0 else 1\n        case _:\n            raise Exception('Incorrect mode value')\n     \n\ndef unzip_file(path, path_to):\n    with zipfile.ZipFile(path, 'r') as zip_ref:\n        zip_ref.extractall(path_to)\n\n\ndef parse_literals(sql : str, table_structure : list[dict]):\n    root = sqlparse.parse(sql)[0]\n    names = []\n\n    def __get_all_names_helper(node : sqlparse.sql.Token):\n        if issubclass(type(node), sqlparse.sql.TokenList):\n            for token in node.tokens:\n                __get_all_names_helper(token)\n        elif node.ttype != sqlparse.sql.T.Punctuation and node.ttype != sqlparse.sql.T.Whitespace:\n            names.append(node.value)\n\n    __get_all_names_helper(root)\n    \n    tables = set([table['table_name'] for table in table_structure])\n    visited_tables = set([])\n    buckets = []\n    for name in names:\n        if name in tables and name not in visited_tables:\n            buckets.append({\n                'table_name' : name,\n                'columns' : []\n            })\n            visited_tables.add(name)\n        elif name not in tables:\n            for table in table_structure:\n                if name in table['columns']:\n                    if table['table_name'] not in visited_tables:\n                        buckets.append({\n                            'table_name' : table['table_name'],\n                            'columns' : [name]\n                        })\n                        visited_tables.add(table['table_name'])\n                    else:\n                        instance = [bucket for bucket in buckets if bucket['table_name'] == table['table_name']][0]\n                        if name not in instance['columns']:\n                            instance['columns'].append(name)\n    \n    return buckets","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import string\nimport pandas as pd\nfrom sqlalchemy import text, Connection\n\n\nclass IterableDataFrame():\n    def __init__(self, df : pd.DataFrame):\n        self.df = df\n        self.__series = {}\n        for idx in self.df.index:\n            sample = {\n                column : self.df[self.df.index == idx][column][idx] for column in self.df.keys()\n            }\n            self.__series[idx] = sample\n\n    def __len__(self):\n        return self.df.shape[0]\n\n    def as_list(self):\n        return list(self.__series.values())\n    \n    def __iter__(self):\n        return iter(self.as_list())\n\n    def __getitem__(self, index):\n        return self.__series[index]\n\n\ndef tables_from_connection(conn : Connection):\n    master = pd.DataFrame(conn.execute(text('SELECT * FROM sqlite_master')).fetchall())\n    tables = list(master[master['type'] == 'table']['name'])\n    return tables\n\n\ndef structure_from_connection(conn : Connection):\n    tables = tables_from_connection(conn)\n    structure = []\n    for table in tables:\n        columns = list(pd.DataFrame(conn.execute(text(f'SELECT * FROM \"{table}\"')).fetchall()).columns)[1:]\n        structure.append(\n            {\n                'table_name' : table,\n                'columns' : columns\n            })\n        \n    return structure\n\n\ndef prepare_column_names(conn : Connection):\n    structure = structure_from_connection(conn)\n    for table in structure:\n        for column in table['columns']:\n            if len((set(string.punctuation) | set(string.whitespace)) & set(column)) != 0:\n                new_name = ''.join([char for char in column if str.isalnum(char)])\n                conn.execute(text(\n                    f'''ALTER TABLE \"{table['table_name']}\" RENAME COLUMN \"{column}\" TO \"{new_name}\"'''\n                ))\n\n        if len((set(string.punctuation) | set(string.whitespace)) & set(table['table_name'])) != 0:\n            new_table_name = ''.join([char for char in table['table_name'] if str.isalnum(char)]);\n            conn.execute(text(f'''ALTER TABLE \"{table['table_name']}\" RENAME TO \"{new_table_name}\"'''))\n\n    return True","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n\nclass PromptBuilder:\n    def __init__(self, question):\n        self.__prompt = ''\n        self.schema_linking = False\n        self.__question = question\n        self.__few_shot = None\n        self.__schema_template = None\n        self.__cell_value_referencing = None\n\n\n    def switch_schema_linking(self, table_structure=None):\n        self.table_structure = table_structure\n        self.schema_linking = not self.schema_linking\n        return self\n\n\n    def add_few_shot(self, sentence_model, target_question, queries):\n        questions = [sample['question'] for sample in queries]\n\n        input_examples = []\n        similar = find_similar_sentences(sentence_model, target_question, questions, count=3)\n        for sample in queries:\n            curr_qs = sample['question']\n            if curr_qs in similar:\n                input_examples.append([curr_qs, sample['query']])\n\n        few_shot_template = ''\n        for ex in input_examples:\n            few_shot_template += f'Q: {ex[0]}\\n'\n            few_shot_template += f'A: {ex[1]}\\n'\n\n        self.__few_shot = few_shot_template\n        return self\n    \n\n    def add_schema_template(self, db_conn):\n        if self.schema_linking:\n            structure = self.table_structure\n        else:\n            structure = structure_from_connection(db_conn)\n\n        schema_template = ''\n        for table in structure:\n            schema_template += f\"{table['table_name']}({', '.join(table['columns'])});\\n\"\n        self.__schema_template = schema_template\n        return self\n\n\n    def add_cell_value_referencing(self, db_conn, count=1):\n        if self.schema_linking:\n            tables = [table['table_name'] for table in self.table_structure]\n        else:\n            tables = tables_from_connection(db_conn)\n\n        data_information = []\n        for table in tables:\n            if self.schema_linking:\n                instance = [bucket for bucket in self.table_structure if bucket['table_name'] == table][0]\n                pd_table = pd.read_sql(f'SELECT * FROM {table}', db_conn)[instance['columns']]\n            else:\n                pd_table = pd.read_sql(f'SELECT * FROM {table}', db_conn)\n            \n            indexes = np.random.randint(0, pd_table.shape[0], size=count)\n            series = [pd_table[pd_table.index == idx].to_numpy() for idx in indexes]\n\n            data_information.append({\n                'table_name' : table,\n                'examples' : [f\"[{', '.join(map(str,list(ser.reshape(ser.shape[1]))))}]\" for ser in series]\n            })\n\n        value_template = ''\n        for data in data_information:\n            value_template += f\"{data['table_name']}({', '.join(data['examples'])});\\n\"\n\n        self.__cell_value_referencing = value_template\n        return self\n\n\n    def include_target(self, number: int):\n        Variations = {\n            1: 'Ответь на вопрос SQLite sql-запросом и без объяснений.\\n',\n            2: ''\n        }\n        return Variations[number]\n\n\n    def include_few_shot(self, number: int):\n        if self.__few_shot is None:\n            raise RuntimeError('Не добавлен few_shot')\n\n        Variations = {\n            1: f'### Примеры похожих запросов и ответы на них:\\n{self.__few_shot}\\n',\n            2: ''\n        }\n        return Variations[number]\n\n\n    def include_schema_template(self, number: int):\n        if self.__schema_template is None:\n            raise RuntimeError('Не добавлен schema_template')\n\n        Variations = {\n            1: f'### Схема таблиц:\\n{self.__schema_template}\\n',\n            2: ''\n        }\n        return Variations[number]\n\n\n    def include_cell_value_referencing(self, number: int):\n        if self.__cell_value_referencing is None:\n            raise RuntimeError('Не добавлен cell_value_referencing')\n\n        Variations = {\n            1: f'### Примеры данных в таблице:\\n{self.__cell_value_referencing}\\n',\n            2: ''\n        }\n        return Variations[number]\n\n\n    def include_question(self, number: int):\n        Variations = {\n            1: f'### Вопрос: {self.__question}\\n### SQL:\\n\\n',\n            2: ''\n        }\n        return Variations[number]\n\n\n    def build_prompt(self, number: int):\n        Variations = {\n            1: {\n                self.include_target : 1,\n                self.include_few_shot : 1,\n                self.include_schema_template : 1,\n                self.include_cell_value_referencing : 1,\n                self.include_question : 1\n            },\n            2: {\n                self.include_question : 1\n            },\n            3:\n            {\n                self.include_cell_value_referencing : 1,\n                self.include_question : 1\n            },\n            4:\n            {\n                self.include_question : 1,\n                self.include_schema_template : 1\n            }\n        }\n\n        for func, value in Variations[number].items():\n                self.__prompt += func(value)  \n\n        return self.__prompt\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import zss\nimport sqlparse\n\n# def pretty_print(node, shift):\n#     print(shift + str(node))\n#     shift += '    '\n#     for token in node.children:\n#         pretty_print(token, shift + '    ')\n\n\nclass SqlNode:\n    def __init__(self, node):\n        self.children = []\n        self.raw_node = node\n        if type(node) == sqlparse.sql.Token or type(node) == sqlparse.sql.Identifier:\n            self.label = str(node.value)\n            return\n        \n        self.label = type(node).__name__\n        for token in node.tokens:\n            if token.is_whitespace:\n                continue\n\n            self.children.append(SqlNode(token))\n\n    def __repr__(self):\n        return str(type(self.raw_node)) + ' ' + self.label\n    \n    @staticmethod\n    def get_children(self):\n        return self.children\n    \n    @staticmethod\n    def get_label(self):\n        return self.label\n\n\ndef dist_comp(node1, node2):\n    return int(node1 != node2)\n\n\ndef ratio(tree1 : SqlNode, tree2 : SqlNode):\n    edit_distance = zss.simple_distance(tree1, tree2, SqlNode.get_children, SqlNode.get_label, dist_comp)\n\n    def __tree_nodes_count(root):\n        cnt = 0\n        for child in root.children:\n            cnt += __tree_nodes_count(child)\n\n        cnt += 1\n        return cnt\n    \n    max_nodes = max(__tree_nodes_count(tree1), __tree_nodes_count(tree2))\n    return max(1 - edit_distance/max_nodes, 0)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!gdown 1Xjbp207zfCaBxhPgt-STB_RxwNo2TIW2\n#unzip_file('merged_database_2022-06-10.zip', 'pauq_databases')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"engine = create_engine('sqlite:////kaggle/input/main-package/main_database.sqlite', echo=False)\nconn = engine.connect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prepare_column_names(conn) # Устраняет пробелы в названии столбцов\nstructure_from_connection(conn)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### Пример использования schema linking\n#structure = structure_from_connection(conn)\n#linked_schema = parse_literals(query, structure)\n\n#prompt = PromptBuilder(question=\"Oh shit, i`m sorry... Sorry for what?\")\n#prompt.switch_schema_linking(linked_schema).add_schema_template(conn).build_prompt(3)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"queries = IterableDataFrame(pd.read_excel('/kaggle/input/main-package/NLSQL.xlsx'))","metadata":{"_cell_guid":"099580ae-cc40-4cb7-bdde-cf2b57ab7a45","_uuid":"9e745e69-8b15-40b1-a7c5-50422b812c19","id":"s3HuFCRpfyxu","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Препроцессинг промпта","metadata":{"_cell_guid":"60baf893-838f-4564-b751-92fdb1ab2a4d","_uuid":"ea5468d0-d708-4c03-aac9-6cca9e60a383","collapsed":false,"id":"bbFNaY5A4KVs","jupyter":{"outputs_hidden":false},"trusted":true}},{"cell_type":"code","source":"sentence_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class HuggingFaceModelInference:\n    def __init__(self, path):\n        self.path = path\n        self.evaluated = False\n        self.is_downloaded = False\n\n\n    def __load_model(self):\n        self.tokenizer = AutoTokenizer.from_pretrained(self.path, trust_remote_code=True)\n        self.model = AutoModelForCausalLM.from_pretrained(\n                    self.path,\n                    torch_dtype=torch.float16,\n                    device_map=\"auto\",\n                    max_memory={0: \"10GiB\", 1: \"10GiB\"},  \n                    offload_folder=\"./offload\", \n                    trust_remote_code=True\n                    )\n\n    def evaluate(self, queries : IterableDataFrame, connection : Connection):\n        if not self.is_downloaded:\n            self.__load_model()\n            self.is_downloaded = True\n\n        self.model.eval()\n        logger = []\n        summary = 0\n        for query in tqdm(queries):\n            question = query['question']\n            gold_sql = query['query']\n\n            builder = PromptBuilder(question)\n            prompt = builder.add_schema_template(connection)\\\n                             .build_prompt(4)\n\n            text = f'''You are an AI programming assistant, utilizing the Deepseek Coder model, developed by Deepseek Company, and you only answer questions related to computer science. For politically sensitive questions, security and privacy issues, and other non-computer science questions, you will refuse to answer.\n                1. Return ONLY valid SQL query without any explanations\n                3. Never repeat the answer\n                4. Format: [SQL]<query>[/SQL]\n                \n                ### Instruction:\n                {prompt}\\n\\n\n                ### Response:'''\n            \n            if self.tokenizer.pad_token is None:\n                self.tokenizer.pad_token = self.tokenizer.eos_token\n\n            with torch.inference_mode():  \n                inputs = self.tokenizer(text,return_tensors=\"pt\").to(self.model.device) \n\n                generate_ids = self.model.generate(\n                                **inputs,\n                                max_length=2048,\n                                num_return_sequences=1,\n                                temperature=0.2, \n                                top_p=0.95,\n                                do_sample=True,\n                                use_cache=True \n                                )\n        \n                output = self.tokenizer.decode(\n                        generate_ids[0, inputs.input_ids.shape[1]:],\n                        skip_special_tokens=True\n                        )\n\n            #pred_sql = re.search(r'Response:(.+)', output, re.DOTALL).group(1).strip()\n            pred_sql =  re.search(r'\\[SQL\\](.*?)\\[\\/SQL\\]', output, re.DOTALL)\n            pred_sql = pred_sql.group(1).strip() if pred_sql else \"error\"\n            logger.append({'question' : question, 'pred' : pred_sql, 'gold' : gold_sql})\n            try:\n                df_pred = pd.read_sql(pred_sql, connection)\n                df_gold = pd.read_sql(gold_sql, connection)\n                summary += table_similarity(df_pred, df_gold, mode='flexible')\n            except:\n                pass\n\n        self.summary = summary\n        self.queries_count = len(queries)\n        self.logger = logger\n        self.evaluated = True\n\n    def accuracy(self):\n        \"\"\"Метрика, характеризующая корректную кодогенерацию модели\"\"\"\n        if not self.evaluated:\n            raise Exception('Model was not been evaluated')\n        return self.summary / self.queries_count\n\n    def sql_similarity(self):\n        \"\"\"Метрика, характеризующая синтаксическую схожесть сгенерированного и истинного кода\"\"\"\n        if not self.evaluated:\n            raise Exception('Model was not been evaluated')\n        vectorized = [[sentence_model.encode(pair[0]), sentence_model.encode(pair[1])] for pair in self.logger]\n        similarities = [sentence_model.similarity(pair[0], pair[1]) for pair in vectorized]\n        return np.mean(similarities)","metadata":{"_cell_guid":"badd3dde-3fb0-433b-9a81-50d83886e96e","_uuid":"8e31e90d-f714-43c9-b231-be1788cbcdc6","collapsed":false,"id":"HBRQjrXdfyxx","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def dump_inference(name: str, exec_time: list, sql_sim, acc):\n    dump = json5.dumps({\n        'name': name,\n        'exec_time': exec_time,\n        'sql_similarity': str(sql_sim),\n        'accuracy': str(acc)\n    })\n    with open(f'{name}_dump.txt', 'w') as w:\n        w.write(dump)","metadata":{"_cell_guid":"2290c3dd-c7b0-40df-97c4-6a91dadca036","_uuid":"7e53bbc2-eb78-408c-899c-9b951b7efad4","collapsed":false,"id":"dcQJKD8Nfyxz","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1. SQLCoder 7b https://huggingface.co/defog/sqlcoder-7b-2","metadata":{"_cell_guid":"59e279e6-9308-465d-aad6-7fa856d74ad2","_uuid":"f9b0239a-cfac-4e3e-8b90-0e9d6ee06664","collapsed":false,"id":"OXTC7kCufyx0","jupyter":{"outputs_hidden":false},"trusted":true}},{"cell_type":"code","source":"#sqlcoder = HuggingFaceModelInference('defog/sqlcoder-7b-2')\n#sqlcoder.evaluate(shuffle(geo_iterable.as_list())[:3], conn)","metadata":{"_cell_guid":"27adee9a-3a22-4869-a3a6-a5d9b84fdafd","_uuid":"02b26db7-9f82-4958-bd91-e60dc1e4c969","id":"vCQKMr7_fyx0","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#sqlcoder.accuracy()","metadata":{"id":"aM5iPZbKfyx1","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#sqlcoder.logger","metadata":{"id":"dbrujfaxfyx2","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## DeepSeek 6.7b","metadata":{}},{"cell_type":"code","source":"deepseek = HuggingFaceModelInference('deepseek-ai/deepseek-coder-6.7b-instruct')\ndeepseek.evaluate(shuffle(queries.as_list())[:10], conn) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. SQLTroughAI (сайт не работает?) https://sqlthroughai.com/","metadata":{"_cell_guid":"90a18636-3f22-45aa-ab2c-a107fa4c6a81","_uuid":"9b45e537-617f-4fe0-b9d0-d623679498d4","collapsed":false,"id":"LC3aWFzjfyx2","jupyter":{"outputs_hidden":false},"trusted":true}},{"cell_type":"markdown","source":"## 3. Chat2DB 7b","metadata":{"_cell_guid":"d55558bc-4b00-4394-bc4f-c0073a11401d","_uuid":"4ae33630-d334-42a2-8cb6-b598829eff96","collapsed":false,"id":"NeSXnH5efyx2","jupyter":{"outputs_hidden":false},"trusted":true}},{"cell_type":"code","source":"# chat2db = HuggingFaceModelInference('Chat2DB/Chat2DB-SQL-7B')\n# chat2db.evaluate(shuffle(dataset)[:20])","metadata":{"_cell_guid":"6331cae7-1f53-4810-bbac-16746766a115","_uuid":"df11395b-e166-4e60-a8c1-177616885682","id":"g2R-FoySfyx2","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# chat2db.accuracy(), chat2db.sql_similarity(), np.mean(chat2db.exec_time)","metadata":{"id":"hMmXGF2efyx3","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# dump_inference('Chat2DB-SQL-7B', chat2db.exec_time, chat2db.sql_similarity(), chat2db.accuracy())","metadata":{"_cell_guid":"4fa7c30a-25e6-4896-a7ef-a48677e4a609","_uuid":"9851857f-6885-4d68-b229-64584ef63b7a","collapsed":false,"id":"J8Fqx7jtfyx3","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4. SQLova (пока пропустим)","metadata":{"_cell_guid":"d2ef533b-4074-4840-869e-2991e312dad4","_uuid":"90e6e293-677b-4df0-b68f-64996050e1cf","collapsed":false,"id":"g-VCg48Zfyx3","jupyter":{"outputs_hidden":false},"trusted":true}},{"cell_type":"code","source":"# !wget https://github.com/naver/sqlova/releases/download/SQLova-parameters/model_bert_best.pt","metadata":{"_cell_guid":"ba7cb3b3-ab6d-44f0-8a29-d5a379d52145","_uuid":"77e847b6-baef-4107-be0a-87e7f35071e1","collapsed":false,"id":"cX6Z6hncfyx3","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from transformers import AutoTokenizer, BertModel\n\n# model = torch.load('model_bert_best.pt', map_location='cpu', weights_only=True)","metadata":{"_cell_guid":"2f8b34f0-37c8-48d5-af01-c172d2a0dd16","_uuid":"cf0f4a02-81fd-438f-af8a-682d0e852963","collapsed":false,"id":"H3VQQEZYfyx3","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5. DuckDB-NSQL 7b","metadata":{"_cell_guid":"36e6679e-f787-4878-9ece-778d696f902a","_uuid":"fb512d0f-8426-42c4-b47f-8842ea420b28","collapsed":false,"id":"tYwLcup9fyx4","jupyter":{"outputs_hidden":false},"trusted":true}},{"cell_type":"code","source":"# duckdb = HuggingFaceModelInference('motherduckdb/DuckDB-NSQL-7B-v0.1')","metadata":{"_cell_guid":"2d0f45a8-7c98-432e-89ab-59345f8f6888","_uuid":"dab98270-0c45-4157-828c-4fc879b8969a","collapsed":false,"id":"Tot4dlxMfyx4","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# duckdb.evaluate(shuffle(dataset)[:30])","metadata":{"id":"hPpuGQcSfyx4","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# duckdb.accuracy(), duckdb.sql_similarity(), np.mean(duckdb.exec_time)","metadata":{"id":"8Q31HSR_fyx4","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# dump_inference('DuckDB-NSQL-7B-v0.1', duckdb.exec_time, duckdb.sql_similarity(), duckdb.accuracy())","metadata":{"_cell_guid":"d43194c8-3f1f-4412-8b2e-a81bc275fe23","_uuid":"11b3e41a-58b2-4081-9782-366f5920fb0e","collapsed":false,"id":"-1cY9b33fyx4","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6. Internlm 8b","metadata":{"_cell_guid":"af04599a-a9e7-408d-bc82-75798187e28e","_uuid":"5f4db0d8-6be6-4fac-ae04-0992df690acc","collapsed":false,"execution":{"iopub.execute_input":"2024-11-08T16:51:16.947229Z","iopub.status.busy":"2024-11-08T16:51:16.946746Z","iopub.status.idle":"2024-11-08T16:51:16.952142Z","shell.execute_reply":"2024-11-08T16:51:16.951198Z","shell.execute_reply.started":"2024-11-08T16:51:16.947189Z"},"id":"311didGcfyx5","jupyter":{"outputs_hidden":false},"trusted":true}},{"cell_type":"code","source":"#!pip install einops -q","metadata":{"_cell_guid":"af6a95a6-d496-43ce-ab55-04a7727b1667","_uuid":"3ea3c4e9-7685-4101-b702-b767efc99200","collapsed":false,"id":"ZLIv6Z_Dfyx5","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# internlm = HuggingFaceModelInference('internlm/internlm2_5-7b')\n# internlm.evaluate(dataset[:20])","metadata":{"_cell_guid":"4c24ecaa-757e-4e30-8178-0160a155118a","_uuid":"85790c77-1a2f-4529-9f3b-5550e1ee2414","collapsed":false,"id":"QncMmDomfyx5","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# dump_inference('internlm2_5-7b', internlm.exec_time, internlm.sql_similarity(), internlm.accuracy())","metadata":{"_cell_guid":"fb7eba11-32e9-41e6-87a6-5773120d014b","_uuid":"d3d1e506-3e4b-4323-8083-5352911894c1","collapsed":false,"id":"KftZCaJofyx5","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Прочее","metadata":{"_cell_guid":"911306e3-b047-451a-abcf-00dbf37fe1c7","_uuid":"1ef8f63d-9d86-4070-9e67-c10675859a72","collapsed":false,"id":"iyJhh7Srfyx6","jupyter":{"outputs_hidden":false},"trusted":true}},{"cell_type":"code","source":"from numba import cuda\nimport gc\n#cuda.devices.gpus[0].reset()\n#cuda.devices.gpus[1].reset()\n#gc.collect()","metadata":{"_cell_guid":"823de476-d607-4c57-9d9e-90c55ecb6b3b","_uuid":"d845407a-9c1d-459b-8c9c-ec713618828e","collapsed":false,"id":"P7KlZTlxfyx6","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null}]}