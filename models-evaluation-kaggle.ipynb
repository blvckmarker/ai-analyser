{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4bef7992-fd1a-44fd-9da7-96fbbae6e0ec",
    "_uuid": "88b99755-8202-4ddf-a578-eb88c8d5c7ed",
    "collapsed": false,
    "id": "5e2Gc4EPfyxl",
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "# Подготовка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "493f2279-ae45-48f1-a03a-10413c2a4d3b",
    "_uuid": "2b1445fe-507d-4d0b-8633-7e7ea3dcc40c",
    "execution": {
     "iopub.execute_input": "2025-04-03T10:17:28.702716Z",
     "iopub.status.busy": "2025-04-03T10:17:28.702484Z",
     "iopub.status.idle": "2025-04-03T10:17:33.084964Z",
     "shell.execute_reply": "2025-04-03T10:17:33.084019Z",
     "shell.execute_reply.started": "2025-04-03T10:17:28.702695Z"
    },
    "id": "b8V36cmgynSD",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install sentence-transformers -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "56d8808c-d33b-497f-aa3d-19de2f2023c8",
    "_uuid": "590a47b4-6c5b-4716-8c0a-117716a6bba0",
    "execution": {
     "iopub.execute_input": "2025-04-03T12:00:16.223716Z",
     "iopub.status.busy": "2025-04-03T12:00:16.223486Z",
     "iopub.status.idle": "2025-04-03T12:00:17.019104Z",
     "shell.execute_reply": "2025-04-03T12:00:17.018415Z",
     "shell.execute_reply.started": "2025-04-03T12:00:16.223696Z"
    },
    "id": "YQ3a_27dyOco",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "#from sentence_transformers import SentenceTransformer\n",
    "#from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import numpy as np\n",
    "#import torch\n",
    "\n",
    "from sqlglot import parse_one\n",
    "from sqlglot.diff import ChangeDistiller\n",
    "\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from prompting import PromptBuilder\n",
    "from sklearn.utils import shuffle\n",
    "from sqlalchemy import Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='alert alert-info'>spans.py</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T12:00:17.021049Z",
     "iopub.status.busy": "2025-04-03T12:00:17.020726Z",
     "iopub.status.idle": "2025-04-03T12:00:17.026893Z",
     "shell.execute_reply": "2025-04-03T12:00:17.025930Z",
     "shell.execute_reply.started": "2025-04-03T12:00:17.021018Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from abc import ABC\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Span(ABC):\n",
    "    pass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ExtendedSqlSpan(Span):\n",
    "    NL : str\n",
    "    sql_gold : str\n",
    "    sql_pred : str\n",
    "    df_soft : int\n",
    "    df_flexible : int\n",
    "    df_gold_IN_df_pred : bool\n",
    "    df_pred_IN_df_gold : bool\n",
    "    df_gold_columns : list[str]\n",
    "    df_pred_columns : list[str]\n",
    "    TED : int\n",
    "    Error : str | None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='alert alert-info'>table_finder.py</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from dataclasses import dataclass\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "@dataclass\n",
    "class DtoColumn:\n",
    "    Name : str\n",
    "    Description : str\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DtoTable:\n",
    "    Name : str\n",
    "    Description : str\n",
    "    Columns : list[DtoColumn]\n",
    "\n",
    "\n",
    "def prepare_df(df: pd.DataFrame) -> list[DtoTable]:\n",
    "    tables = []\n",
    "\n",
    "    for table in tqdm(df['table'].unique()):\n",
    "        t : pd.DataFrame = df[df['table'] == table]\n",
    "        columns : list[DtoColumn] = []\n",
    "        for idx in t.index:\n",
    "            name = str(t[t.index == idx]['field'][idx]).strip()\n",
    "            desc = str(t[t.index == idx]['field_description'][idx]).strip()\n",
    "\n",
    "            column = DtoColumn(name, desc)\n",
    "            columns.append(column)\n",
    "\n",
    "        dto_table = DtoTable(table, str(t['table_description'][idx]).strip(), columns)\n",
    "        tables.append(dto_table)\n",
    "\n",
    "    return tables\n",
    "\n",
    "\n",
    "def generate_table_profile(table : DtoTable) -> str:\n",
    "    profile = []\n",
    "    \n",
    "    profile.append(f\"Таблица: {table.Name}\")\n",
    "    profile.append(f\"Описание таблицы: {table.Description}\")\n",
    "\n",
    "    profile.append(\"Колонки:\")\n",
    "    for col in table.Columns:\n",
    "        profile.append(f\"- {col.Name} - {col.Description}\")\n",
    "    \n",
    "    return \"\\n\".join(profile)\n",
    "\n",
    "\n",
    "class TableFinder:\n",
    "    def __init__(self, tables):\n",
    "        self.model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")\n",
    "        self.table_profiles = [generate_table_profile(t) for t in tables]\n",
    "        self.table_embeddings = self.model.encode(self.table_profiles)\n",
    "        self.tables = tables\n",
    "    \n",
    "    def find_tables(self, question: str, top_k: int = 5) :\n",
    "        question_embedding = self.model.encode(question)\n",
    "        \n",
    "        similarities = []\n",
    "        for emb in self.table_embeddings:\n",
    "            cos_sim = np.dot(question_embedding, emb) / (\n",
    "                np.linalg.norm(question_embedding) * np.linalg.norm(emb)\n",
    "            )\n",
    "            similarities.append(cos_sim)\n",
    "        \n",
    "        sorted_indices = np.argsort(similarities)[::-1]\n",
    "        return [(self.tables[i], similarities[i]) for i in sorted_indices[:top_k]]\n",
    "\n",
    "\n",
    "class HybridFinder(TableFinder):\n",
    "    def __init__(self, tables):\n",
    "        super().__init__(tables)\n",
    "        self.tfidf = TfidfVectorizer()\n",
    "        self.tfidf_matrix = self.tfidf.fit_transform(self.table_profiles)\n",
    "    \n",
    "    def find_tables(self, question: str, top_k: int = 5, alpha: float = 0.7, verbose : bool = False):\n",
    "        semantic_scores = np.array([ex[1] for ex in super().find_tables(question, top_k=len(self.tables))])\n",
    "        \n",
    "        question_tfidf = self.tfidf.transform([question])\n",
    "        keyword_scores = np.dot(question_tfidf, self.tfidf_matrix.T).toarray()[0]\n",
    "        \n",
    "        combined_scores = alpha * semantic_scores + (1 - alpha) * keyword_scores\n",
    "        sorted_indices = np.argsort(combined_scores)[::-1]\n",
    "        if verbose:\n",
    "            return [(self.tables[i], combined_scores[i]) for i in sorted_indices[:top_k]]\n",
    "        else:\n",
    "            return [self.tables[i] for i in sorted_indices[:top_k]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='alert alert-info'>general.py</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T11:31:39.974810Z",
     "iopub.status.busy": "2025-04-03T11:31:39.974384Z",
     "iopub.status.idle": "2025-04-03T11:32:06.308769Z",
     "shell.execute_reply": "2025-04-03T11:32:06.308073Z",
     "shell.execute_reply.started": "2025-04-03T11:31:39.974773Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import util\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "from sqlglot import exp\n",
    "import sqlglot.optimizer\n",
    "import re\n",
    "from pandas.testing import assert_frame_equal, assert_series_equal\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class ExcelIO(object):\n",
    "    @staticmethod\n",
    "    def write_spans(spans : list[Span], path : str):\n",
    "        asdict = [span.__dict__ for span in spans]\n",
    "        df = pd.DataFrame(asdict)\n",
    "        df.to_excel(excel_writer=path, index=False)\n",
    "\n",
    "    @staticmethod\n",
    "    def read_excel(path : str):\n",
    "        df = pd.read_excel(path)\n",
    "        return df\n",
    "\n",
    "\n",
    "def find_similar_sentences(sentence_model, target_sentence : str, sentences : list[str], count : int = 3):\n",
    "    \"\"\"\n",
    "    Функция поиска похожих по смыслу предложений из набора `sentences` для указанного предложения `target_sentence`\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sentence_model : Any\n",
    "        Модель, позволяющая векторизовать текст\n",
    "    target_sentence: str\n",
    "        Предложение, для которого нужно найти похожие по смыслу предложения\n",
    "    sentences : List[str]\n",
    "        Набор предложений\n",
    "    count : int\n",
    "        Количество ожидаемых предложений\n",
    "    \"\"\"\n",
    "\n",
    "    emb_target = sentence_model.encode(target_sentence)\n",
    "\n",
    "    sims = []\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        emb_sentence = sentence_model.encode(sentence)\n",
    "        sim = util.pytorch_cos_sim(emb_sentence, emb_target)\n",
    "        sims.append([i, np.float16(sim.squeeze())])\n",
    "\n",
    "    nearest = sorted(sims, key=lambda pair : pair[1], reverse=True)\n",
    "    similar_questions = [sentences[pair[0]] for pair in nearest if pair[1] != 1.0][:count]\n",
    "    return similar_questions\n",
    "\n",
    "\n",
    "def find_sql(text : str, start_keyword='SELECT'):\n",
    "    \"\"\"\n",
    "    Функция, которая ищет в строке `text` первое вхождение самого длинного, правильного SQL запроса\n",
    "    \"\"\"\n",
    "\n",
    "    matches = re.search(f'({start_keyword}).*', text, flags=re.IGNORECASE|re.DOTALL)\n",
    "    if not matches:\n",
    "        return ''\n",
    "\n",
    "    begin_sql = matches.group()\n",
    "    splitted = begin_sql.split()\n",
    "\n",
    "    maybe_sql = ''\n",
    "    last_success_pos = 0\n",
    "    for i, word in enumerate(splitted):\n",
    "        maybe_sql += f' {word}'\n",
    "        try:\n",
    "            sqlglot.transpile(maybe_sql)\n",
    "            last_success_pos = i\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    found_sql = ' '.join(splitted[:last_success_pos + 1])\n",
    "    return found_sql\n",
    "\n",
    "\n",
    "\n",
    "def table_similarity(dataframe1 : pd.DataFrame, dataframe2 : pd.DataFrame, mode : str) -> int:\n",
    "    \"\"\"\n",
    "    Функция сравнения двух таблиц\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe1 : pd.DataFrame\n",
    "        Первая таблица\n",
    "    dataframe2 : pd.DataFrame\n",
    "        Вторая таблица\n",
    "    mode : str\n",
    "        Режим сравнения. Допустимы режимы soft, strict, flexible\n",
    "    \"\"\"\n",
    "\n",
    "    # if dataframe1.columns.shape != dataframe2.columns.shape:\n",
    "    #     return False\n",
    "    # if not (dataframe1.columns == dataframe2.columns).all():\n",
    "    #     return False\n",
    "    \n",
    "    match mode:\n",
    "        case 'soft':\n",
    "            return int(subset_df(dataframe1, dataframe2) and subset_df(dataframe2, dataframe1))\n",
    "        case 'strict':\n",
    "            return int(dataframe1.equals(dataframe2))\n",
    "        case 'flexible':\n",
    "            hash_1 = set(pd.util.hash_pandas_object(dataframe1, index=False))\n",
    "            hash_2 = set(pd.util.hash_pandas_object(dataframe2, index=False))\n",
    "            intersection = hash_1 & hash_2\n",
    "            union = hash_1 | hash_2\n",
    "\n",
    "            return len(intersection) / len(union) if len(union) != 0 else 1\n",
    "        case _:\n",
    "            raise Exception('Incorrect mode value')\n",
    "     \n",
    "\n",
    "\n",
    "def unzip_file(path, path_to):\n",
    "    with zipfile.ZipFile(path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(path_to)\n",
    "\n",
    "\n",
    "\n",
    "def schema_parse(sql : str, structure_dict : dict):\n",
    "    \"\"\"\n",
    "    Функция, вытягивающая все названия таблиц и столбцов, которые упомянуты в запросе `sql`\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sql : str\n",
    "        SQL запрос\n",
    "    table_structure : List[dict]\n",
    "        Структура таблицы, которая может быть получена при помощи функции `structure_from_connection`\n",
    "    \"\"\"\n",
    "\n",
    "    optimized_sql = sqlglot.optimizer.optimize(\n",
    "        sqlglot.parse_one(sql),\n",
    "        schema=structure_dict\n",
    "    )\n",
    "\n",
    "    buckets = {table.name : set(structure_dict[table.name].keys()) for table in optimized_sql.find_all(exp.Table)}\n",
    "    # for column in optimized_sql.find_all(exp.Column):\n",
    "    #     table_of_col = column.table\n",
    "    #     buckets[table_of_col].add(column.name)\n",
    "\n",
    "    as_default = []\n",
    "    for k, v in buckets.items():\n",
    "        as_default.append({'table_name' : k, 'columns' : list(v)})\n",
    "\n",
    "    return as_default\n",
    "\n",
    "\n",
    "def normalize_table(\n",
    "    df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Normalizes a dataframe by:\n",
    "    1. sorting columns in alphabetical order\n",
    "    2. sorting rows using values from first column to last\n",
    "    3. resetting index\n",
    "    \"\"\"\n",
    "    sorted_df = df.reindex(sorted(df.columns), axis=1)\n",
    "    sorted_df = sorted_df.sort_values(by=list(sorted_df.columns))\n",
    "    sorted_df = sorted_df.reset_index(drop=True)\n",
    "\n",
    "    return sorted_df\n",
    "\n",
    "\n",
    "def subset_df(\n",
    "    df_sub: pd.DataFrame,\n",
    "    df_super: pd.DataFrame,\n",
    "    verbose: bool = False,\n",
    ") -> bool:\n",
    "    \n",
    "    if df_sub.empty:\n",
    "        return True  \n",
    "    \n",
    "    df_super_temp = df_super.copy(deep=True)\n",
    "    matched_columns = []\n",
    "    for col_sub_name in df_sub.columns:\n",
    "        col_match = False\n",
    "        for col_super_name in df_super_temp.columns:\n",
    "            col_sub = df_sub[col_sub_name].sort_values().reset_index(drop=True)\n",
    "            col_super = (\n",
    "                df_super_temp[col_super_name].sort_values().reset_index(drop=True)\n",
    "            )\n",
    "            try:\n",
    "                assert_series_equal(\n",
    "                    col_sub, col_super, check_dtype=False, check_names=False\n",
    "                )\n",
    "                col_match = True\n",
    "                matched_columns.append(col_super_name)\n",
    "                df_super_temp = df_super_temp.drop(columns=[col_super_name])\n",
    "                break\n",
    "            except AssertionError:\n",
    "                continue\n",
    "        if col_match == False:\n",
    "            if verbose:\n",
    "                print(f\"no match for {col_sub_name}\")\n",
    "            return False\n",
    "    df_sub_normalized = normalize_table(df_sub)\n",
    "\n",
    "    df_super_matched = df_super[matched_columns].rename(\n",
    "        columns=dict(zip(matched_columns, df_sub.columns))\n",
    "    )\n",
    "    df_super_matched = normalize_table(df_super_matched)\n",
    "\n",
    "    try:\n",
    "        assert_frame_equal(df_sub_normalized, df_super_matched, check_dtype=False)\n",
    "        return True\n",
    "    except AssertionError:\n",
    "        return False\n",
    "    \n",
    "\n",
    "\n",
    "def dto_tables_from_dataframe(df: pd.DataFrame) -> list[DtoTable]: \n",
    "    tables = []\n",
    "\n",
    "    for table in tqdm(df['table'].unique()):\n",
    "        t : pd.DataFrame = df[df['table'] == table]\n",
    "        columns : list[DtoColumn] = []\n",
    "        for idx in t.index:\n",
    "            name = str(t[t.index == idx]['field'][idx]).strip()\n",
    "            desc = str(t[t.index == idx]['field_description'][idx]).strip()\n",
    "\n",
    "            column = DtoColumn(name, desc)\n",
    "            columns.append(column)\n",
    "\n",
    "        dto_table = DtoTable(table, str(t['table_description'][idx]).strip(), columns)\n",
    "        tables.append(dto_table)\n",
    "\n",
    "    return tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='alert alert-info'>dataset.py</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T12:00:17.028122Z",
     "iopub.status.busy": "2025-04-03T12:00:17.027887Z",
     "iopub.status.idle": "2025-04-03T12:00:17.045694Z",
     "shell.execute_reply": "2025-04-03T12:00:17.044807Z",
     "shell.execute_reply.started": "2025-04-03T12:00:17.028103Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import text, Connection, inspect\n",
    "\n",
    "\n",
    "class IterableDataFrame:\n",
    "    \"\"\"\n",
    "    Класс, позволяющий итерироваться в таблице типа `pd.DataFrame`\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df : pd.DataFrame):\n",
    "        self.df = df\n",
    "        self.__series = {}\n",
    "        for idx in self.df.index:\n",
    "            sample = {\n",
    "                column : self.df[self.df.index == idx][column][idx] for column in self.df.keys()\n",
    "            }\n",
    "            self.__series[idx] = sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __as_list(self):\n",
    "        return list(self.__series.values())\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return iter(self.__as_list())\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.__as_list()[index]\n",
    "    \n",
    "    def at_index(self, index):\n",
    "        return self.__series[index]\n",
    "\n",
    "\n",
    "def tables_from_connection(conn : Connection):\n",
    "    \"\"\"\n",
    "    Функция, возвращающая список названий всех таблиц для данного соединения `conn`\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    conn : sqlalchemy.Connection\n",
    "        Соединение с базой данных\n",
    "    \"\"\"\n",
    "\n",
    "    master = pd.DataFrame(conn.execute(text('SELECT * FROM sqlite_master')).fetchall())\n",
    "    tables = list(master[master['type'] == 'table']['name'])\n",
    "    return tables\n",
    "\n",
    "\n",
    "def structure_from_connection(conn : Connection):\n",
    "    \"\"\"\n",
    "    Функция, возвращающая список словарей вида {table_name, columns}, где table_name - str, а columns - List[str]\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    conn : sqlalchemy.Connection\n",
    "        Соединение с базой данных\n",
    "    \"\"\"\n",
    "\n",
    "    tables = tables_from_connection(conn)\n",
    "    structure = []\n",
    "    for table in tables:\n",
    "        columns = pd.DataFrame(conn.execute(text(f'SELECT * FROM \"{table}\"')).fetchall()).columns.to_list()\n",
    "        structure.append(\n",
    "            {\n",
    "                'table_name' : table,\n",
    "                'columns' : columns\n",
    "            })\n",
    "        \n",
    "    return structure\n",
    "\n",
    "\n",
    "def structure_from_connection_dict(conn : Connection):\n",
    "    \"\"\"\n",
    "    Функция, возвращающая словарь словарей вида {\"Table\" : {\"Col\" : \"INT\", ...}}\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    conn : sqlalchemy.Connection\n",
    "        Соединение с базой данных\n",
    "    \"\"\"\n",
    "\n",
    "    tables = tables_from_connection(conn)\n",
    "    structure = {}\n",
    "    for table in tables:\n",
    "        columns = inspect(conn).get_columns(table)\n",
    "        columns_meta = {column['name'] : column['type'] for column in columns}\n",
    "        structure[table] = columns_meta\n",
    "\n",
    "    return structure\n",
    "\n",
    "\n",
    "def prepare_column_names(conn : Connection):\n",
    "    \"\"\"\n",
    "    Функция, обрабатывающая базу данных из соединения `conn`. Функция переименовывает названия всех таблиц и их столбцов, \n",
    "    которые содержат whitespace и punctuation символы. Возвращает True, если переименовывание прошло успешно\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    conn : sqlalchemy.Connection\n",
    "        Соединение с базой данных\n",
    "    \"\"\"\n",
    "    \n",
    "    structure = structure_from_connection(conn)\n",
    "    for table in structure:\n",
    "        for column in table['columns']:\n",
    "            new_name = str.lower(''.join([char for char in column if str.isalnum(char)]))\n",
    "            if new_name != column:\n",
    "                conn.execute(text(\n",
    "                    f'''ALTER TABLE \"{table['table_name']}\" RENAME COLUMN \"{column}\" TO \"{new_name}\"'''\n",
    "                ))\n",
    "\n",
    "        new_table_name = str.lower(''.join([char for char in table['table_name'] if str.isalnum(char)]))\n",
    "        if new_table_name != table['table_name']:\n",
    "            conn.execute(text(f'''ALTER TABLE \"{table['table_name']}\" RENAME TO \"{new_table_name}\"'''))\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='alert alert-info'>prompting.py</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T12:00:17.046808Z",
     "iopub.status.busy": "2025-04-03T12:00:17.046608Z",
     "iopub.status.idle": "2025-04-03T12:00:17.066243Z",
     "shell.execute_reply": "2025-04-03T12:00:17.065444Z",
     "shell.execute_reply.started": "2025-04-03T12:00:17.046791Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlalchemy\n",
    "\n",
    "class PromptBuilder:\n",
    "    \"\"\"\n",
    "    Класс, отвечающий за создание промпта на основе указанных фичей\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.__prompt = ''\n",
    "        self.schema_linking = False\n",
    "\n",
    "\n",
    "    def add_schema_linking(self, table_structure=None):\n",
    "        \"\"\"\n",
    "        Метод, добавляющий режим использования фичи Schema Linking. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        table_structure : Any\n",
    "            Структура таблицы, которая может быть получена с помощью функции `structure_from_connection`\n",
    "        \"\"\"\n",
    "\n",
    "        self.table_structure = table_structure\n",
    "        self.schema_linking = True\n",
    "        return self\n",
    "\n",
    "\n",
    "    def add_few_shot(self, \n",
    "                     queries : IterableDataFrame, \n",
    "                     target_question : str, \n",
    "                     sentence_model, \n",
    "                     count : int = 1):\n",
    "        \"\"\"\n",
    "        Метод, отвечающий за добавление фичи Few-Shot в промпт\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        sentence_model : Any\n",
    "            Модель, позволяющая векторизовать текст\n",
    "        target_question : str\n",
    "            Вопрос, для которого нужно найти похожие по смыслу вопросы\n",
    "        queries : IterableDataFrame\n",
    "            Набор вопросов и запросов, среди которых нужно найти ближайшие по смыслу вопросы. Объект должен являться матрицей Nx2\n",
    "        count : int\n",
    "        \"\"\"\n",
    "\n",
    "        questions = [sample['question'] for sample in queries]\n",
    "\n",
    "        input_examples = []\n",
    "        similar = find_similar_sentences(sentence_model, target_question, questions, count)\n",
    "        for sample in queries:\n",
    "            curr_qs = sample['question']\n",
    "            if curr_qs in similar:\n",
    "                input_examples.append([curr_qs, sample['query']])\n",
    "\n",
    "        few_shot_template = ''\n",
    "        for ex in input_examples:\n",
    "            few_shot_template += f'Q: {ex[0]}\\n'\n",
    "            few_shot_template += f'A: {ex[1]}\\n'\n",
    "\n",
    "        self.__prompt += few_shot_template + '\\n'\n",
    "        return self\n",
    "    \n",
    "\n",
    "    def add_schema_template_from_connection(self, db_conn : sqlalchemy.Connection):\n",
    "        \"\"\"\n",
    "        Метод, отвечающий за добавление фичи Schema Template в промпт через соедиенение с БД\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        db_conn : sqlalchemy.Connection\n",
    "            Соединение с базой данных\n",
    "        \"\"\"\n",
    "\n",
    "        if self.schema_linking:\n",
    "            structure = self.table_structure\n",
    "        else:\n",
    "            structure = structure_from_connection(db_conn)\n",
    "\n",
    "        schema_template = ''\n",
    "        for table in structure:\n",
    "            schema_template += f\"{table['table_name']}({', '.join(table['columns'])});\\n\"\n",
    "\n",
    "        self.__prompt += schema_template + '\\n'\n",
    "        return self\n",
    "\n",
    "\n",
    "    def add_schema_template_from_dto_tables(self, dto_tables : list[DtoTable]):\n",
    "        \"\"\"\n",
    "        Метод, отвечающий за добавление фичи Schema Template в промпт через список объектов типа DtoTable\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        db_conn : sqlalchemy.Connection\n",
    "            Соединение с базой данных\n",
    "        \"\"\"\n",
    "        structure = []\n",
    "        for dto_table in dto_tables:\n",
    "            columns = [column.Name for column in dto_table.Columns]\n",
    "            structure.append({\n",
    "                'table_name' : dto_table.Name,\n",
    "                'columns' : columns\n",
    "            })\n",
    "\n",
    "        schema_template = ''\n",
    "        for table in structure:\n",
    "            schema_template += f\"{table['table_name']}({', '.join(table['columns'])});\\n\"\n",
    "\n",
    "        self.__prompt += schema_template + '\\n'\n",
    "        return self\n",
    "\n",
    "\n",
    "    def add_cell_value_referencing(self, db_conn : sqlalchemy.Connection, count=1):\n",
    "        \"\"\"\n",
    "        Метод, отвечающий за добавление фичи Cell Value Referencing в промпт\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        db_conn : sqlalchemy.Connection\n",
    "            Соединение с базой данных\n",
    "        count : int\n",
    "            Ожидаемое количество примеров для добавления. По умолчанию равно 1\n",
    "        \"\"\"\n",
    "\n",
    "        if self.schema_linking:\n",
    "            tables = [table['table_name'] for table in self.table_structure]\n",
    "        else:\n",
    "            tables = tables_from_connection(db_conn)\n",
    "\n",
    "        data_information = []\n",
    "        for table in tables:\n",
    "            if self.schema_linking:\n",
    "                instance = [bucket for bucket in self.table_structure if bucket['table_name'] == table][0]\n",
    "                pd_table = pd.read_sql(f'SELECT * FROM {table}', db_conn)[instance['columns']]\n",
    "            else:\n",
    "                pd_table = pd.read_sql(f'SELECT * FROM {table}', db_conn)\n",
    "            \n",
    "            indexes = np.random.randint(0, pd_table.shape[0], size=count)\n",
    "            series = [pd_table[pd_table.index == idx].to_numpy() for idx in indexes]\n",
    "\n",
    "            data_information.append({\n",
    "                'table_name' : table,\n",
    "                'examples' : [f\"[{', '.join(map(str,list(ser.reshape(ser.shape[1]))))}]\" for ser in series]\n",
    "            })\n",
    "\n",
    "        value_template = ''\n",
    "        for data in data_information:\n",
    "            value_template += f\"{data['table_name']}({', '.join(data['examples'])});\\n\"\n",
    "\n",
    "        self.__prompt += value_template + '\\n'\n",
    "        return self\n",
    "\n",
    "\n",
    "    def add_message(self, message : str):\n",
    "        self.__prompt += message + '\\n'\n",
    "        return self\n",
    "\n",
    "\n",
    "    def build_prompt(self):\n",
    "        return self.__prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='alert alert-info'>models-evaluation.ipynb</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T12:00:18.022131Z",
     "iopub.status.busy": "2025-04-03T12:00:18.021826Z",
     "iopub.status.idle": "2025-04-03T12:00:18.063516Z",
     "shell.execute_reply": "2025-04-03T12:00:18.062560Z",
     "shell.execute_reply.started": "2025-04-03T12:00:18.022110Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:////kaggle/input/main-database/main_database.sqlite', echo=False)\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T12:00:19.277306Z",
     "iopub.status.busy": "2025-04-03T12:00:19.277017Z",
     "iopub.status.idle": "2025-04-03T12:00:20.634830Z",
     "shell.execute_reply": "2025-04-03T12:00:20.634108Z",
     "shell.execute_reply.started": "2025-04-03T12:00:19.277285Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "prepare_column_names(conn) # Устраняет пробелы в названии столбцов\n",
    "queries = IterableDataFrame(pd.read_excel('/kaggle/input/main-database/NLSQL.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = pd.read_excel('table-main.xlsx')\n",
    "meta_tables = dto_tables_from_dataframe(meta_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder = HybridFinder(meta_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "60baf893-838f-4564-b751-92fdb1ab2a4d",
    "_uuid": "ea5468d0-d708-4c03-aac9-6cca9e60a383",
    "collapsed": false,
    "id": "bbFNaY5A4KVs",
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "# Препроцессинг промпта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T13:13:47.383650Z",
     "iopub.status.busy": "2025-03-27T13:13:47.383086Z",
     "iopub.status.idle": "2025-03-27T13:13:51.146224Z",
     "shell.execute_reply": "2025-03-27T13:13:51.145558Z",
     "shell.execute_reply.started": "2025-03-27T13:13:47.383623Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2942d7612c9409d8180a6b3cfbf849d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77b851ea405645cb99431625fa0aaf0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d63b7b82911642b8b726471d7368999c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd99b39856d64b4382e590b1ff198dbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "659bdd0347074a2680a7e8c9485eec16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc965b61f8214753b76dbc4f1b9a2ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "500554c905b3401489665313d12e2de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d7d7bf482e45aa9ec131fd9d4da567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ad55571dd44eadbd614da22fe39bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baebb1cea87d49a19d0bf11419fc7667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c173303d98040d8be60e45a11b1f77a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "badd3dde-3fb0-433b-9a81-50d83886e96e",
    "_uuid": "8e31e90d-f714-43c9-b231-be1788cbcdc6",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-03-27T13:35:41.580758Z",
     "iopub.status.busy": "2025-03-27T13:35:41.580462Z",
     "iopub.status.idle": "2025-03-27T13:35:41.593994Z",
     "shell.execute_reply": "2025-03-27T13:35:41.593310Z",
     "shell.execute_reply.started": "2025-03-27T13:35:41.580738Z"
    },
    "id": "HBRQjrXdfyxx",
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class HuggingFaceModelInference:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.evaluated = False\n",
    "        self.is_downloaded = False\n",
    "\n",
    "\n",
    "    def __load_model(self):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.path, trust_remote_code=True)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "                    self.path,\n",
    "                    torch_dtype=torch.float16,\n",
    "                    device_map=\"auto\",\n",
    "                    max_memory={0: \"10GiB\", 1: \"10GiB\"},  \n",
    "                    offload_folder=\"./offload\", \n",
    "                    trust_remote_code=True\n",
    "                    )\n",
    "\n",
    "    def __inference(self, prompt):\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "        with torch.inference_mode():  \n",
    "            inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.model.device) \n",
    "            generate_ids = self.model.generate(\n",
    "                            **inputs,\n",
    "                            max_length=2048,\n",
    "                            num_return_sequences=1,\n",
    "                            temperature=0.2, \n",
    "                            top_p=0.95,\n",
    "                            do_sample=True,\n",
    "                            use_cache=True \n",
    "                            )\n",
    "    \n",
    "            output = self.tokenizer.decode(\n",
    "                    generate_ids[0, inputs.input_ids.shape[1]:],\n",
    "                    skip_special_tokens=True\n",
    "                    )\n",
    "            \n",
    "        return output\n",
    "    \n",
    "\n",
    "    def evaluate(self, queries : IterableDataFrame, connection : Connection):\n",
    "        if not self.is_downloaded:\n",
    "            self.__load_model()\n",
    "            self.is_downloaded = True\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        logger : list[ExtendedSqlSpan] = []\n",
    "        summary = 0\n",
    "        for query in tqdm(queries):\n",
    "            question = query['question']\n",
    "            gold_sql = query['query']\n",
    "\n",
    "            found_tables = finder.find_tables(question, alpha=0.4, top_k=1)\n",
    "\n",
    "            prompt = PromptBuilder()\\\n",
    "                .add_message('### You are an expert SQL developer with deep knowledge of database optimization, correct syntax, and efficient query design. Your task is to generate accurate, performant SQL queries based on the provided input.')\\\n",
    "                .add_message(\"### Table schema:\")\\\n",
    "                .add_schema_template_from_dto_tables(found_tables)\\\n",
    "                .add_message(\"### Examples of data\")\\\n",
    "                .add_cell_value_referencing(conn, count=1)\\\n",
    "                .add_message(f\"### Your task: {question}\")\\\n",
    "                .build_prompt()\n",
    "            \n",
    "\n",
    "            output = self.__inference(prompt)\n",
    "            pred_sql = find_sql(output, start_keyword='SELECT')\n",
    "            transpiled_sql = sqlglot.transpile(pred_sql, write=sqlglot.Dialects.SQLITE)\n",
    "            \n",
    "            sql_span = self.__make_excel_span(question,\n",
    "                                                transpiled_sql, \n",
    "                                                gold_sql, \n",
    "                                                connection)\n",
    "            \n",
    "            summary += sql_span.df_flexible\n",
    "            logger.append(sql_span)\n",
    "        \n",
    "        self.summary = summary\n",
    "        self.queries_count = len(queries)\n",
    "        self.logger = logger\n",
    "        self.evaluated = True\n",
    "\n",
    "\n",
    "    def accuracy(self):\n",
    "        \"\"\"\n",
    "        Значение метрики Accuracy для последнего запуска модели\n",
    "        \"\"\"\n",
    "\n",
    "        if not self.evaluated:\n",
    "            raise Exception('Model was not been evaluated')\n",
    "        \n",
    "        return self.summary / self.queries_count\n",
    "    \n",
    "\n",
    "    def __make_excel_span(self,\n",
    "                    question : str,\n",
    "                    pred_sql : str,\n",
    "                    gold_sql : str, \n",
    "                    connection : Connection) -> ExtendedSqlSpan:\n",
    "        \n",
    "        df_gold = pd.read_sql(gold_sql, connection)\n",
    "\n",
    "        try:\n",
    "            df_pred = pd.read_sql(pred_sql, connection)\n",
    "            \n",
    "            span_df_soft        = table_similarity(df_pred, df_gold, mode='soft')\n",
    "            span_df_flexible    = table_similarity(df_pred, df_gold, mode='flexible')\n",
    "            span_gold_IN_pred   = subset_df(df_gold, df_pred)\n",
    "            span_pred_IN_gold   = subset_df(df_pred, df_gold)\n",
    "            span_pred_columns   = df_pred.columns.to_list()\n",
    "            span_ted            = self.__ted_compare(pred_sql, gold_sql)\n",
    "            span_error          = None\n",
    "        except Exception as exception:\n",
    "            span_df_soft        = .0\n",
    "            span_df_flexible    = .0\n",
    "            span_gold_IN_pred   = False\n",
    "            span_pred_IN_gold   = False\n",
    "            span_pred_columns   = []\n",
    "            span_ted            = self.__ted_compare(pred_sql, gold_sql)\n",
    "            span_error          = exception\n",
    "\n",
    "        sql_span = ExtendedSqlSpan(\n",
    "                NL                 =question,\n",
    "                sql_gold           =gold_sql,\n",
    "                sql_pred           =pred_sql,\n",
    "                df_soft            =span_df_soft,\n",
    "                df_flexible        =span_df_flexible,\n",
    "                df_pred_IN_df_gold =span_pred_IN_gold,\n",
    "                df_gold_IN_df_pred =span_gold_IN_pred,\n",
    "                df_gold_columns    =df_gold.columns.to_list(),\n",
    "                df_pred_columns    =span_pred_columns,\n",
    "                TED                =span_ted,\n",
    "                Error              =span_error\n",
    "            )\n",
    "        \n",
    "        return sql_span\n",
    "\n",
    "    def __ted_compare(self, sql1 : str, sql2 : str):\n",
    "        \"\"\"\n",
    "        Компоратор для двух деревьев\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            exp1 = parse_one(sql1)\n",
    "            exp2 = parse_one(sql2)\n",
    "        except:\n",
    "            return .0\n",
    "\n",
    "        distiller = ChangeDistiller()\n",
    "        _ = distiller.diff(exp1, exp2)\n",
    "        return distiller._dice_coefficient(exp1, exp2)\n",
    "\n",
    "\n",
    "    def TED(self):\n",
    "        \"\"\"\n",
    "        Значение метрики Tree Edit Distance для последнего запуска модели\n",
    "        \"\"\"\n",
    "\n",
    "        if not self.evaluated:\n",
    "            raise Exception('Model was not been evaluated')\n",
    "        \n",
    "        summary = 0\n",
    "        for span in self.logger:\n",
    "            summary += self.__ted_compare(span.sql_pred, span.sql_gold)\n",
    "\n",
    "        return summary / self.queries_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "59e279e6-9308-465d-aad6-7fa856d74ad2",
    "_uuid": "f9b0239a-cfac-4e3e-8b90-0e9d6ee06664",
    "collapsed": false,
    "id": "OXTC7kCufyx0",
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## 1. SQLCoder 7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "27adee9a-3a22-4869-a3a6-a5d9b84fdafd",
    "_uuid": "02b26db7-9f82-4958-bd91-e60dc1e4c969",
    "execution": {
     "iopub.execute_input": "2025-03-27T13:13:51.163846Z",
     "iopub.status.busy": "2025-03-27T13:13:51.163480Z",
     "iopub.status.idle": "2025-03-27T13:13:51.238442Z",
     "shell.execute_reply": "2025-03-27T13:13:51.237657Z",
     "shell.execute_reply.started": "2025-03-27T13:13:51.163810Z"
    },
    "id": "vCQKMr7_fyx0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#sqlcoder = HuggingFaceModelInference('defog/sqlcoder-7b-2')\n",
    "#sqlcoder.evaluate(shuffle(queries), conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T13:13:51.239414Z",
     "iopub.status.busy": "2025-03-27T13:13:51.239184Z",
     "iopub.status.idle": "2025-03-27T13:13:51.250493Z",
     "shell.execute_reply": "2025-03-27T13:13:51.249788Z",
     "shell.execute_reply.started": "2025-03-27T13:13:51.239394Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#conn.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T13:13:51.251483Z",
     "iopub.status.busy": "2025-03-27T13:13:51.251296Z",
     "iopub.status.idle": "2025-03-27T13:13:51.261343Z",
     "shell.execute_reply": "2025-03-27T13:13:51.260538Z",
     "shell.execute_reply.started": "2025-03-27T13:13:51.251466Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#ExcelIO.write_spans(sqlcoder.logger, 'out.xlsx')\n",
    "#sqlcoder.accuracy(), sqlcoder.TED()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T13:13:51.262223Z",
     "iopub.status.busy": "2025-03-27T13:13:51.262002Z",
     "iopub.status.idle": "2025-03-27T13:13:51.273111Z",
     "shell.execute_reply": "2025-03-27T13:13:51.272492Z",
     "shell.execute_reply.started": "2025-03-27T13:13:51.262201Z"
    },
    "id": "aM5iPZbKfyx1",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#sqlcoder.accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T13:13:51.274346Z",
     "iopub.status.busy": "2025-03-27T13:13:51.274026Z",
     "iopub.status.idle": "2025-03-27T13:13:51.285892Z",
     "shell.execute_reply": "2025-03-27T13:13:51.285120Z",
     "shell.execute_reply.started": "2025-03-27T13:13:51.274299Z"
    },
    "id": "dbrujfaxfyx2",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#sqlcoder.logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepSeek 6.7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "deepseek = HuggingFaceModelInference('deepseek-ai/deepseek-coder-6.7b-instruct')\n",
    "deepseek.evaluate(shuffle(queries), conn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T13:48:38.492003Z",
     "iopub.status.busy": "2025-03-27T13:48:38.491667Z",
     "iopub.status.idle": "2025-03-27T13:48:38.597726Z",
     "shell.execute_reply": "2025-03-27T13:48:38.596634Z",
     "shell.execute_reply.started": "2025-03-27T13:48:38.491978Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7906976744186046, 0.8952091523033922)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ExcelIO.write_spans(deepseek.logger, 'out.xlsx')\n",
    "deepseek.accuracy(), deepseek.TED()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d55558bc-4b00-4394-bc4f-c0073a11401d",
    "_uuid": "4ae33630-d334-42a2-8cb6-b598829eff96",
    "collapsed": false,
    "id": "NeSXnH5efyx2",
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## 3. Chat2DB 7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "6331cae7-1f53-4810-bbac-16746766a115",
    "_uuid": "df11395b-e166-4e60-a8c1-177616885682",
    "execution": {
     "iopub.execute_input": "2025-03-27T13:22:15.624315Z",
     "iopub.status.busy": "2025-03-27T13:22:15.623982Z",
     "iopub.status.idle": "2025-03-27T13:22:15.627220Z",
     "shell.execute_reply": "2025-03-27T13:22:15.626610Z",
     "shell.execute_reply.started": "2025-03-27T13:22:15.624282Z"
    },
    "id": "g2R-FoySfyx2",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# chat2db = HuggingFaceModelInference('Chat2DB/Chat2DB-SQL-7B')\n",
    "# chat2db.evaluate(shuffle(queries), conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T13:22:15.628011Z",
     "iopub.status.busy": "2025-03-27T13:22:15.627829Z",
     "iopub.status.idle": "2025-03-27T13:22:15.646410Z",
     "shell.execute_reply": "2025-03-27T13:22:15.645811Z",
     "shell.execute_reply.started": "2025-03-27T13:22:15.627994Z"
    },
    "id": "hMmXGF2efyx3",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#ExcelIO.write_spans(chat2db.logger, 'out.xlsx')\n",
    "#chat2db.accuracy(), chat2db.TED()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "36e6679e-f787-4878-9ece-778d696f902a",
    "_uuid": "fb512d0f-8426-42c4-b47f-8842ea420b28",
    "collapsed": false,
    "id": "tYwLcup9fyx4",
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## 5. DuckDB-NSQL 7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "2d0f45a8-7c98-432e-89ab-59345f8f6888",
    "_uuid": "dab98270-0c45-4157-828c-4fc879b8969a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-03-27T13:22:15.647337Z",
     "iopub.status.busy": "2025-03-27T13:22:15.647050Z",
     "iopub.status.idle": "2025-03-27T13:22:15.662446Z",
     "shell.execute_reply": "2025-03-27T13:22:15.661815Z",
     "shell.execute_reply.started": "2025-03-27T13:22:15.647302Z"
    },
    "id": "Tot4dlxMfyx4",
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#duckdb = HuggingFaceModelInference('motherduckdb/DuckDB-NSQL-7B-v0.1')\n",
    "#duckdb.evaluate(shuffle(queries), conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T13:22:15.663463Z",
     "iopub.status.busy": "2025-03-27T13:22:15.663244Z",
     "iopub.status.idle": "2025-03-27T13:22:15.675026Z",
     "shell.execute_reply": "2025-03-27T13:22:15.674437Z",
     "shell.execute_reply.started": "2025-03-27T13:22:15.663438Z"
    },
    "id": "8Q31HSR_fyx4",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#ExcelIO.write_spans(duckdb.logger, 'out.xlsx')\n",
    "#duckdb.accuracy(), duckdb.TED()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "d43194c8-3f1f-4412-8b2e-a81bc275fe23",
    "_uuid": "11b3e41a-58b2-4081-9782-366f5920fb0e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-03-27T13:22:15.676219Z",
     "iopub.status.busy": "2025-03-27T13:22:15.675911Z",
     "iopub.status.idle": "2025-03-27T13:22:15.689303Z",
     "shell.execute_reply": "2025-03-27T13:22:15.688590Z",
     "shell.execute_reply.started": "2025-03-27T13:22:15.676188Z"
    },
    "id": "-1cY9b33fyx4",
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# dump_inference('DuckDB-NSQL-7B-v0.1', duckdb.exec_time, duckdb.sql_similarity(), duckdb.accuracy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "911306e3-b047-451a-abcf-00dbf37fe1c7",
    "_uuid": "1ef8f63d-9d86-4070-9e67-c10675859a72",
    "collapsed": false,
    "id": "iyJhh7Srfyx6",
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## Прочее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "823de476-d607-4c57-9d9e-90c55ecb6b3b",
    "_uuid": "d845407a-9c1d-459b-8c9c-ec713618828e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-03-27T13:22:15.692197Z",
     "iopub.status.busy": "2025-03-27T13:22:15.691939Z",
     "iopub.status.idle": "2025-03-27T13:22:17.312309Z",
     "shell.execute_reply": "2025-03-27T13:22:17.311640Z",
     "shell.execute_reply.started": "2025-03-27T13:22:15.692142Z"
    },
    "id": "P7KlZTlxfyx6",
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "import gc\n",
    "#cuda.devices.gpus[0].reset()\n",
    "#cuda.devices.gpus[1].reset()\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T11:56:01.848416Z",
     "iopub.status.busy": "2025-04-03T11:56:01.848145Z",
     "iopub.status.idle": "2025-04-03T11:59:11.084249Z",
     "shell.execute_reply": "2025-04-03T11:59:11.083140Z",
     "shell.execute_reply.started": "2025-04-03T11:56:01.848386Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T11:59:48.524542Z",
     "iopub.status.busy": "2025-04-03T11:59:48.524230Z",
     "iopub.status.idle": "2025-04-03T12:00:16.222462Z",
     "shell.execute_reply": "2025-04-03T12:00:16.221791Z",
     "shell.execute_reply.started": "2025-04-03T11:59:48.524514Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 2048\n",
    "dtype = None \n",
    "load_in_4bit = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T12:05:12.300037Z",
     "iopub.status.busy": "2025-04-03T12:05:12.299572Z",
     "iopub.status.idle": "2025-04-03T12:05:41.897692Z",
     "shell.execute_reply": "2025-04-03T12:05:41.896883Z",
     "shell.execute_reply.started": "2025-04-03T12:05:12.299994Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.3.19: Fast Gemma patching. Transformers: 4.50.3.\n",
      "   \\\\   /|    Tesla P100-PCIE-16GB. Num GPUs = 1. Max memory: 15.888 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 6.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/gemma-7b-bnb-4bit\", # Choose ANY! eg teknium/OpenHermes-2.5-Mistral-7B\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    device_map='auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T12:08:09.386024Z",
     "iopub.status.busy": "2025-04-03T12:08:09.385682Z",
     "iopub.status.idle": "2025-04-03T12:08:16.252690Z",
     "shell.execute_reply": "2025-04-03T12:08:16.252007Z",
     "shell.execute_reply.started": "2025-04-03T12:08:09.385998Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.3.19 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T12:08:17.933502Z",
     "iopub.status.busy": "2025-04-03T12:08:17.933125Z",
     "iopub.status.idle": "2025-04-03T12:08:18.721272Z",
     "shell.execute_reply": "2025-04-03T12:08:18.720570Z",
     "shell.execute_reply.started": "2025-04-03T12:08:17.933462Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "prompt = PromptBuilder()\\\n",
    "        .add_message('### Тебе будет дан некоторый вопрос, на основании которого уже другая модель потом сгенерирует SQL запрос. Твоя же задача исправить всевозможные неопределенности в этом вопросе, которые могут повлиять на кодогенерацию. Например:')\\\n",
    "        .add_message('### Задача написать исправленный вопрос и только. Если в вопросе всё определенно, то исправлять его не нужно. Помимо этого тебе будет так же дана схема базы данных')\\\n",
    "        .add_message('### Схема баз данных')\\\n",
    "        .add_schema_template(conn)\\\n",
    "        .add_message('### Ответ выведи в формате [START] ответ [END]')\\\n",
    "        .add_message(f'### Вопрос: {queries[10][\"question\"]}')\\\n",
    "        .add_message('### Исправленный вопрос:')\\\n",
    "        .build_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T12:09:20.474584Z",
     "iopub.status.busy": "2025-04-03T12:09:20.474271Z",
     "iopub.status.idle": "2025-04-03T12:09:20.478896Z",
     "shell.execute_reply": "2025-04-03T12:09:20.478029Z",
     "shell.execute_reply.started": "2025-04-03T12:09:20.474559Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Тебе будет дан некоторый вопрос, на основании которого уже другая модель потом сгенерирует SQL запрос. Твоя же задача исправить всевозможные неопределенности в этом вопросе, которые могут повлиять на кодогенерацию. Например:\n",
      "### Задача написать исправленный вопрос и только. Если в вопросе всё определенно, то исправлять его не нужно. Помимо этого тебе будет так же дана схема базы данных\n",
      "### Схема баз данных\n",
      "остатки2024(артикул, номенклатура, ед, 01042024, 02042024, 03042024, 04042024, 05042024, 06042024, 07042024, 08042024, 09042024, 10042024, 11042024, 12042024, 13042024, 14042024, 15042024, 16042024, 17042024, 18042024, 19042024, 20042024, 21042024, 22042024, 23042024, 24042024, 25042024, 26042024, 27042024, 28042024, 29042024, 30042024, итого);\n",
      "остатки2023(артикул, номенклатура, ед, 01042023, 02042023, 03042023, 04042023, 05042023, 06042023, 07042023, 08042023, 09042023, 10042023, 11042023, 12042023, 13042023, 14042023, 15042023, 16042023, 17042023, 18042023, 19042023, 20042023, 21042023, 22042023, 23042023, 24042023, 25042023, 26042023, 27042023, 28042023, 29042023, 30042023, итого);\n",
      "продажи(период, регистратор, номерстроки, артикул, номенклатура, документ, код, контрагент, ставкандс, организация, заказпокупателя, подразделение, склад, ответственный, номенклатуранабора, проект, количество, сумма, втчндс, суммабезскидки, себестоимость, себестоимостьбезндс, хозяйственнаяоперация);\n",
      "\n",
      "### Ответ выведи в формате [START] ответ [END]\n",
      "### Вопрос: Вывести все строки, где себестоимость без НДС больше 1000 рублей.\n",
      "### Исправленный вопрос:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T12:08:20.555380Z",
     "iopub.status.busy": "2025-04-03T12:08:20.554964Z",
     "iopub.status.idle": "2025-04-03T12:08:20.561237Z",
     "shell.execute_reply": "2025-04-03T12:08:20.560398Z",
     "shell.execute_reply.started": "2025-04-03T12:08:20.555343Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T12:08:27.245280Z",
     "iopub.status.busy": "2025-04-03T12:08:27.244965Z",
     "iopub.status.idle": "2025-04-03T12:08:34.572407Z",
     "shell.execute_reply": "2025-04-03T12:08:34.571643Z",
     "shell.execute_reply.started": "2025-04-03T12:08:27.245258Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>### Тебе будет дан некоторый вопрос, на основании которого уже другая модель потом сгенерирует SQL запрос. Твоя же задача исправить всевозможные неопределенности в этом вопросе, которые могут повлиять на кодогенерацию. Например:\n",
      "### Задача написать исправленный вопрос и только. Если в вопросе всё определенно, то исправлять его не нужно. Помимо этого тебе будет так же дана схема базы данных\n",
      "### Схема баз данных\n",
      "остатки2024(артикул, номенклатура, ед, 01042024, 02042024, 03042024, 04042024, 05042024, 06042024, 07042024, 08042024, 09042024, 10042024, 11042024, 12042024, 13042024, 14042024, 15042024, 16042024, 17042024, 18042024, 19042024, 20042024, 21042024, 22042024, 23042024, 24042024, 25042024, 26042024, 27042024, 28042024, 29042024, 30042024, итого);\n",
      "остатки2023(артикул, номенклатура, ед, 01042023, 02042023, 03042023, 04042023, 05042023, 06042023, 07042023, 08042023, 09042023, 10042023, 11042023, 12042023, 13042023, 14042023, 15042023, 16042023, 17042023, 18042023, 19042023, 20042023, 21042023, 22042023, 23042023, 24042023, 25042023, 26042023, 27042023, 28042023, 29042023, 30042023, итого);\n",
      "продажи(период, регистратор, номерстроки, артикул, номенклатура, документ, код, контрагент, ставкандс, организация, заказпокупателя, подразделение, склад, ответственный, номенклатуранабора, проект, количество, сумма, втчндс, суммабезскидки, себестоимость, себестоимостьбезндс, хозяйственнаяоперация);\n",
      "\n",
      "### Ответ выведи в формате [START] ответ [END]\n",
      "### Вопрос: Вывести все строки, где себестоимость без НДС больше 1000 рублей.\n",
      "### Исправленный вопрос:\n",
      "### Ответ:\n",
      "<eos>\n"
     ]
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "inputs = tokenizer(prompt, return_tensors = \"pt\").to(model.device)\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n",
    "print(tokenizer.batch_decode(outputs)[0])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6946224,
     "sourceId": 11136692,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
