{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class='alert alert-danger'>\n",
        "<b>Косяки:</b>\n",
        "\n",
        "1. Сравнение таблиц не работает достаточно гибко для датафреймов с разными количествами столбцов\n",
        "2. Не осуществлен автоматический перебор вариантов для `build_prompt`\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class='alert alert-warning'>\n",
        "<b>Нюансы:</b>\n",
        "\n",
        "1. Для тестирования моделей необходимы два объекта: непосредственно соединение с базой данных и таблица с запросами к этим данным.\n",
        "Таблица с запросами должна удовлетворять одному условию - она должна состоять из столбцов с названиями 'question' и 'query'.\n",
        "К базе данных строгих требований нет.\n",
        "\n",
        "2. Существуют, по крайней мере, два модуля в питоне, которые предоставляют интерфейс взаимодействия с базами данных SQlite -- sqlite3 и sqlalchemy. \n",
        "Мы будем пользоваться модулем sqlalchemy по той простой причине, что он позволяет напрямую читать .xlsx таблицы как SQlite базу данных. Важно, что в библиотеке\n",
        "sqlite3, чтобы сделать запрос в бд, надо написать строку вида `conn.execute(query)`, где query - str. В sqlalchemy немного иначе - `conn.execute(text(query))`;\n",
        "функция text лежит в этом же модуле. \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4bef7992-fd1a-44fd-9da7-96fbbae6e0ec",
        "_uuid": "88b99755-8202-4ddf-a578-eb88c8d5c7ed",
        "collapsed": false,
        "id": "5e2Gc4EPfyxl",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "source": [
        "## Загрузка необходимых модулей и датасета"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "493f2279-ae45-48f1-a03a-10413c2a4d3b",
        "_uuid": "2b1445fe-507d-4d0b-8633-7e7ea3dcc40c",
        "execution": {
          "iopub.execute_input": "2024-12-04T13:09:35.072300Z",
          "iopub.status.busy": "2024-12-04T13:09:35.071598Z",
          "iopub.status.idle": "2024-12-04T13:09:46.817749Z",
          "shell.execute_reply": "2024-12-04T13:09:46.816565Z",
          "shell.execute_reply.started": "2024-12-04T13:09:35.072232Z"
        },
        "id": "b8V36cmgynSD",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install json5 gdown sentence-transformers -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "56d8808c-d33b-497f-aa3d-19de2f2023c8",
        "_uuid": "590a47b4-6c5b-4716-8c0a-117716a6bba0",
        "execution": {
          "iopub.execute_input": "2024-12-04T13:09:46.819971Z",
          "iopub.status.busy": "2024-12-04T13:09:46.819688Z",
          "iopub.status.idle": "2024-12-04T13:10:16.172718Z",
          "shell.execute_reply": "2024-12-04T13:10:16.171740Z",
          "shell.execute_reply.started": "2024-12-04T13:09:46.819944Z"
        },
        "id": "YQ3a_27dyOco",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import numpy as np\n",
        "from utils.general import *\n",
        "import torch\n",
        "\n",
        "from sqlglot import parse_one\n",
        "from sqlglot.diff import ChangeDistiller\n",
        "from spans import *\n",
        "\n",
        "from sqlalchemy import create_engine\n",
        "from prompting import PromptBuilder\n",
        "from sklearn.utils import shuffle\n",
        "from sqlalchemy import Connection\n",
        "from utils.dataset import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "engine = create_engine('sqlite:///main_database.sqlite', echo=False)\n",
        "conn = engine.connect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prepare_column_names(conn) # Устраняет пробелы в названии столбцов\n",
        "queries = IterableDataFrame(pd.read_excel('NLSQL.xlsx'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "60baf893-838f-4564-b751-92fdb1ab2a4d",
        "_uuid": "ea5468d0-d708-4c03-aac9-6cca9e60a383",
        "collapsed": false,
        "id": "bbFNaY5A4KVs",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "source": [
        "# Препроцессинг промпта"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "64840261-2c1b-4465-a27f-d7ad5c98cb1b",
        "_uuid": "48755d5c-c9c8-4028-8ff7-a6b5aebc4d9d",
        "execution": {
          "iopub.status.busy": "2024-12-03T12:29:09.956075Z",
          "iopub.status.idle": "2024-12-03T12:29:09.956362Z",
          "shell.execute_reply": "2024-12-03T12:29:09.956242Z",
          "shell.execute_reply.started": "2024-12-03T12:29:09.956227Z"
        },
        "id": "dZjzp_vLfyxw",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "sentence_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "badd3dde-3fb0-433b-9a81-50d83886e96e",
        "_uuid": "8e31e90d-f714-43c9-b231-be1788cbcdc6",
        "execution": {
          "iopub.execute_input": "2024-12-02T18:02:45.231125Z",
          "iopub.status.busy": "2024-12-02T18:02:45.230817Z",
          "iopub.status.idle": "2024-12-02T18:02:45.255546Z",
          "shell.execute_reply": "2024-12-02T18:02:45.254705Z",
          "shell.execute_reply.started": "2024-12-02T18:02:45.231097Z"
        },
        "id": "HBRQjrXdfyxx",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class HuggingFaceModelInference:\n",
        "    def __init__(self, path):\n",
        "        self.path = path\n",
        "        self.evaluated = False\n",
        "        self.is_downloaded = False\n",
        "\n",
        "\n",
        "    def __load_model(self):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self.path, trust_remote_code=True)\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "                    self.path,\n",
        "                    torch_dtype=torch.float16,\n",
        "                    device_map=\"auto\",\n",
        "                    max_memory={0: \"10GiB\", 1: \"10GiB\"},  \n",
        "                    offload_folder=\"./offload\", \n",
        "                    trust_remote_code=True\n",
        "                    )\n",
        "\n",
        "    def __inference(self, prompt):\n",
        "        if self.tokenizer.pad_token is None:\n",
        "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "        with torch.inference_mode():  \n",
        "            inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.model.device) \n",
        "            generate_ids = self.model.generate(\n",
        "                            **inputs,\n",
        "                            max_length=2048,\n",
        "                            num_return_sequences=1,\n",
        "                            temperature=0.2, \n",
        "                            top_p=0.95,\n",
        "                            do_sample=True,\n",
        "                            use_cache=True \n",
        "                            )\n",
        "    \n",
        "            output = self.tokenizer.decode(\n",
        "                    generate_ids[0, inputs.input_ids.shape[1]:],\n",
        "                    skip_special_tokens=True\n",
        "                    )\n",
        "            \n",
        "        return output\n",
        "    \n",
        "\n",
        "    def evaluate(self, queries : IterableDataFrame, connection : Connection):\n",
        "        if not self.is_downloaded:\n",
        "            self.__load_model()\n",
        "            self.is_downloaded = True\n",
        "\n",
        "        self.model.eval()\n",
        "\n",
        "        logger : list[ExtendedSqlSpan] = []\n",
        "        summary = 0\n",
        "        for query in tqdm(queries):\n",
        "            question = query['question']\n",
        "            gold_sql = query['query']\n",
        "\n",
        "            prompt = PromptBuilder()\\\n",
        "                .add_message('### You are an expert SQL developer with deep knowledge of database optimization, correct syntax, and efficient query design. Your task is to generate accurate, performant SQL queries based on the provided input.')\\\n",
        "                .add_message(\"### Table schema:\")\\\n",
        "                .add_schema_template(conn)\\\n",
        "                .add_message(\"### Examples of data\")\\\n",
        "                .add_cell_value_referencing(conn, count=1)\\\n",
        "                .add_message(f\"### Your task: {question}\")\\\n",
        "                .build_prompt()\n",
        "            \n",
        "\n",
        "            output = self.__inference(prompt)\n",
        "            pred_sql = find_sql(output, start_keyword='SELECT')\n",
        "            \n",
        "            df_gold = pd.read_sql(gold_sql, connection)\n",
        "            try:\n",
        "                df_pred = pd.read_sql(pred_sql, connection)\n",
        "                \n",
        "                span_df_soft        = table_similarity(df_pred, df_gold, mode='soft')\n",
        "                span_df_flexible    = table_similarity(df_pred, df_gold, mode='flexible')\n",
        "                span_gold_IN_pred   = False #\n",
        "                span_pred_IN_gold   = False # Добавить проверку\n",
        "                span_pred_columns   = df_pred.columns.to_list()\n",
        "                span_ted            = self.__ted_compare(pred_sql, gold_sql)  \n",
        "            except:\n",
        "                # По определению полагаем\n",
        "                span_df_soft        = .0\n",
        "                span_df_flexible    = .0\n",
        "                span_gold_IN_pred   = False\n",
        "                span_pred_IN_gold   = False\n",
        "                span_pred_columns   = []\n",
        "                span_ted            = .0\n",
        "\n",
        "\n",
        "            sql_span = ExtendedSqlSpan(\n",
        "                    NL                 =question,\n",
        "                    sql_gold           =gold_sql,\n",
        "                    sql_pred           =pred_sql,\n",
        "                    df_soft            =span_df_soft,\n",
        "                    df_flexible        =span_df_flexible,\n",
        "                    df_pred_IN_df_gold =span_pred_IN_gold,\n",
        "                    df_gold_IN_df_pred =span_gold_IN_pred,\n",
        "                    df_gold_columns    =df_gold.columns.to_list(),\n",
        "                    df_pred_columns    =span_pred_columns,\n",
        "                    TED                =span_ted\n",
        "                )\n",
        "            \n",
        "            summary += span_df_flexible\n",
        "            logger.append(sql_span)\n",
        "        \n",
        "        self.summary = summary\n",
        "        self.queries_count = len(queries)\n",
        "        self.logger = logger\n",
        "        self.evaluated = True\n",
        "\n",
        "\n",
        "    def accuracy(self):\n",
        "        \"\"\"\n",
        "        Значение метрики Accuracy для последнего запуска модели\n",
        "        \"\"\"\n",
        "\n",
        "        if not self.evaluated:\n",
        "            raise Exception('Model was not been evaluated')\n",
        "        \n",
        "        return self.summary / self.queries_count\n",
        "    \n",
        "\n",
        "    def __ted_compare(self, sql1 : str, sql2 : str):\n",
        "        \"\"\"\n",
        "        Компоратор для двух деревьев\n",
        "        \"\"\"\n",
        "        \n",
        "        try:\n",
        "            exp1 = parse_one(sql1)\n",
        "            exp2 = parse_one(sql2)\n",
        "        except:\n",
        "            return .0\n",
        "\n",
        "        distiller = ChangeDistiller()\n",
        "        _ = distiller.diff(exp1, exp2)\n",
        "        return distiller._dice_coefficient(exp1, exp2)\n",
        "\n",
        "\n",
        "    def TED(self):\n",
        "        \"\"\"\n",
        "        Значение метрики Tree Edit Distance для последнего запуска модели\n",
        "        \"\"\"\n",
        "\n",
        "        if not self.evaluated:\n",
        "            raise Exception('Model was not been evaluated')\n",
        "        \n",
        "        summary = 0\n",
        "        for span in self.logger:\n",
        "            summary += self.__ted_compare(span.sql_pred, span.sql_gold)\n",
        "\n",
        "        return summary / self.queries_count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "59e279e6-9308-465d-aad6-7fa856d74ad2",
        "_uuid": "f9b0239a-cfac-4e3e-8b90-0e9d6ee06664",
        "collapsed": false,
        "id": "OXTC7kCufyx0",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "source": [
        "## 1. SQLCoder 7b "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "27adee9a-3a22-4869-a3a6-a5d9b84fdafd",
        "_uuid": "02b26db7-9f82-4958-bd91-e60dc1e4c969",
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2024-12-02T18:02:45.258207Z",
          "iopub.status.busy": "2024-12-02T18:02:45.257843Z",
          "iopub.status.idle": "2024-12-02T18:10:00.680821Z",
          "shell.execute_reply": "2024-12-02T18:10:00.679883Z",
          "shell.execute_reply.started": "2024-12-02T18:02:45.258165Z"
        },
        "id": "vCQKMr7_fyx0",
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "sqlcoder = HuggingFaceModelInference('defog/sqlcoder-7b-2')\n",
        "sqlcoder.evaluate(shuffle(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2024-12-02T18:11:26.985804Z",
          "iopub.status.busy": "2024-12-02T18:11:26.984881Z",
          "iopub.status.idle": "2024-12-02T18:11:28.237055Z",
          "shell.execute_reply": "2024-12-02T18:11:28.236120Z",
          "shell.execute_reply.started": "2024-12-02T18:11:26.985769Z"
        },
        "id": "aM5iPZbKfyx1",
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "sqlcoder.accuracy(), sqlcoder.sql_similarity(), np.mean(sqlcoder.exec_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2024-12-02T18:11:45.734500Z",
          "iopub.status.busy": "2024-12-02T18:11:45.734136Z",
          "iopub.status.idle": "2024-12-02T18:11:45.741494Z",
          "shell.execute_reply": "2024-12-02T18:11:45.740679Z",
          "shell.execute_reply.started": "2024-12-02T18:11:45.734468Z"
        },
        "id": "dbrujfaxfyx2",
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "sqlcoder.logger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DeepSeek coder 6.7b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "deepseek = HuggingFaceModelInference('deepseek-ai/deepseek-coder-6.7b-instruct')\n",
        "deepseek.evaluate(shuffle(queries.as_list())[:10], conn) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d55558bc-4b00-4394-bc4f-c0073a11401d",
        "_uuid": "4ae33630-d334-42a2-8cb6-b598829eff96",
        "collapsed": false,
        "id": "NeSXnH5efyx2",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "source": [
        "## 3. Chat2DB 7b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6331cae7-1f53-4810-bbac-16746766a115",
        "_uuid": "df11395b-e166-4e60-a8c1-177616885682",
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2024-12-02T17:12:09.427825Z",
          "iopub.status.busy": "2024-12-02T17:12:09.427437Z",
          "iopub.status.idle": "2024-12-02T17:13:14.571814Z",
          "shell.execute_reply": "2024-12-02T17:13:14.570891Z",
          "shell.execute_reply.started": "2024-12-02T17:12:09.427793Z"
        },
        "id": "g2R-FoySfyx2",
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# chat2db = HuggingFaceModelInference('Chat2DB/Chat2DB-SQL-7B')\n",
        "# chat2db.evaluate(shuffle(dataset)[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2024-12-02T17:13:24.942041Z",
          "iopub.status.busy": "2024-12-02T17:13:24.941195Z",
          "iopub.status.idle": "2024-12-02T17:13:25.801628Z",
          "shell.execute_reply": "2024-12-02T17:13:25.800743Z",
          "shell.execute_reply.started": "2024-12-02T17:13:24.942006Z"
        },
        "id": "hMmXGF2efyx3",
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# chat2db.accuracy(), chat2db.sql_similarity(), np.mean(chat2db.exec_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4fa7c30a-25e6-4896-a7ef-a48677e4a609",
        "_uuid": "9851857f-6885-4d68-b229-64584ef63b7a",
        "id": "J8Fqx7jtfyx3",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# dump_inference('Chat2DB-SQL-7B', chat2db.exec_time, chat2db.sql_similarity(), chat2db.accuracy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "36e6679e-f787-4878-9ece-778d696f902a",
        "_uuid": "fb512d0f-8426-42c4-b47f-8842ea420b28",
        "collapsed": false,
        "id": "tYwLcup9fyx4",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "source": [
        "## 5. DuckDB-NSQL 7b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2d0f45a8-7c98-432e-89ab-59345f8f6888",
        "_uuid": "dab98270-0c45-4157-828c-4fc879b8969a",
        "execution": {
          "iopub.execute_input": "2024-12-02T17:21:47.697990Z",
          "iopub.status.busy": "2024-12-02T17:21:47.697359Z",
          "iopub.status.idle": "2024-12-02T17:21:47.701968Z",
          "shell.execute_reply": "2024-12-02T17:21:47.701064Z",
          "shell.execute_reply.started": "2024-12-02T17:21:47.697946Z"
        },
        "id": "Tot4dlxMfyx4",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# duckdb = HuggingFaceModelInference('motherduckdb/DuckDB-NSQL-7B-v0.1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2024-12-02T17:32:16.001291Z",
          "iopub.status.busy": "2024-12-02T17:32:16.000509Z",
          "iopub.status.idle": "2024-12-02T17:33:47.564041Z",
          "shell.execute_reply": "2024-12-02T17:33:47.562937Z",
          "shell.execute_reply.started": "2024-12-02T17:32:16.001257Z"
        },
        "id": "hPpuGQcSfyx4",
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# duckdb.evaluate(shuffle(dataset)[:30])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-02T17:39:31.191655Z",
          "iopub.status.busy": "2024-12-02T17:39:31.190792Z",
          "iopub.status.idle": "2024-12-02T17:39:32.556694Z",
          "shell.execute_reply": "2024-12-02T17:39:32.555918Z",
          "shell.execute_reply.started": "2024-12-02T17:39:31.191610Z"
        },
        "id": "8Q31HSR_fyx4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# duckdb.accuracy(), duckdb.sql_similarity(), np.mean(duckdb.exec_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "911306e3-b047-451a-abcf-00dbf37fe1c7",
        "_uuid": "1ef8f63d-9d86-4070-9e67-c10675859a72",
        "collapsed": false,
        "id": "iyJhh7Srfyx6",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "source": [
        "## Прочее"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "823de476-d607-4c57-9d9e-90c55ecb6b3b",
        "_uuid": "d845407a-9c1d-459b-8c9c-ec713618828e",
        "execution": {
          "iopub.execute_input": "2024-12-02T16:44:21.761572Z",
          "iopub.status.busy": "2024-12-02T16:44:21.760909Z",
          "iopub.status.idle": "2024-12-02T16:44:24.122804Z",
          "shell.execute_reply": "2024-12-02T16:44:24.121915Z",
          "shell.execute_reply.started": "2024-12-02T16:44:21.761539Z"
        },
        "id": "P7KlZTlxfyx6",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from numba import cuda\n",
        "import gc\n",
        "cuda.devices.gpus[0].reset()\n",
        "cuda.devices.gpus[1].reset()\n",
        "gc.collect()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 6212694,
          "sourceId": 10078210,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30787,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
