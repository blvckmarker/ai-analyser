{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "html"
        }
      },
      "source": [
        "<div class='alert alert-info'>\n",
        "<text style='color:black;'>\n",
        "<b>Послание о ноутбуке</b>\n",
        "<p>\n",
        "1 В начале была загрузка всех необходимых библиотек и модулей.\n",
        "\n",
        "2 Затем явилась переменная `conn`, которая отвечала за соединение с исходной базой данных.\n",
        "\n",
        "3 И переменная эта была типа `sqlalchemy.Connection`, который несколько отличается от похожего по названию типа `sqlite3.Connection`. Ясней начертано в разделе \"Нюансы\".\n",
        "\n",
        "4 И была вскоре предварительно обработана база данных с помощью функции `prepare_column_names`, которая переименовывала все столбцы и таблицы с нерадивыми названиями.\n",
        "\n",
        "5 И стала переменная `queries` типа `IterableDataFrame`, отвечающая за таблицу с вопросами и ответами\n",
        "\n",
        "6 И вот господствующий класс `HuggingFaceModelInference`, который всему был свет. Его главным методом был метод `evaluate`, который и нёс всю суть. \n",
        "\n",
        "7 Метод этот вначале подгружал указанную в конструкторе модель.\n",
        "\n",
        "8 И позже начинался порочный цикл, в котором являлось чадо с названием `builder`. Чадо это возводило промпт, исходя из базы данных `connection` и перечисленных фичей. \n",
        "\n",
        "9 И в чёртовом котле варились переменные `input` и `output`, которые были входными токенами модели и сгенерированным ответом соответственно.\n",
        "\n",
        "10 И пыталась переменная `pred_sql` регулярным ковшом вытянуть оттуда сгенерированный самородок.\n",
        "\n",
        "11 И сравнивались вскоре переменные `pred_sql` и `gold_sql`, выясняя, является ли самородок подлинным или нет.\n",
        "\n",
        "12 Так и заканчивался порочный цикл.\n",
        "\n",
        "13 Обрабатывал метод этот ряд моделей, в число которого вошли SQLCoder, Deepseek, ChatDB и DuckDB.\n",
        "</p>\n",
        "</text>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class='alert alert-danger'>\n",
        "<text style='color:black;'>\n",
        "<b>Косяки:</b>\n",
        "\n",
        "1. Schema linking не распознает спецификатор *\n",
        "2. Сравнение таблиц не работает достаточно гибко для датафреймов с разными количествами столбцов\n",
        "3. Использование регулярного выражения для вытягивания ответа модели несёт риск потери информации. Такой подход неустойчив\n",
        "4. Не осуществлен автоматический перебор вариантов для `build_prompt`\n",
        "</text>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class='alert alert-warning'>\n",
        "<text style='color:black;'>\n",
        "<b>Нюансы:</b>\n",
        "\n",
        "1. Для тестирования моделей необходимы два объекта: непосредственно соединение с базой данных и таблица с запросами к этим данным.\n",
        "Таблица с запросами должна удовлетворять одному условию - она должна состоять из столбцов с названиями 'question' и 'query'.\n",
        "К базе данных строгих требований нет.\n",
        "\n",
        "2. Существуют, по крайней мере, два модуля в питоне, которые предоставляют интерфейс взаимодействия с базами данных SQlite -- sqlite3 и sqlalchemy. \n",
        "Мы будем пользоваться модулем sqlalchemy по той простой причине, что он позволяет напрямую читать .xlsx таблицы как SQlite базу данных. Важно, что в библиотеке\n",
        "sqlite3, чтобы сделать запрос в бд, надо написать строку вида `conn.execute(query)`, где query - str. В sqlalchemy немного иначе - `conn.execute(text(query))`;\n",
        "функция text лежит в этом же модуле. \n",
        "</text>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4bef7992-fd1a-44fd-9da7-96fbbae6e0ec",
        "_uuid": "88b99755-8202-4ddf-a578-eb88c8d5c7ed",
        "collapsed": false,
        "id": "5e2Gc4EPfyxl",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "source": [
        "## Загрузка необходимых модулей и датасета"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "493f2279-ae45-48f1-a03a-10413c2a4d3b",
        "_uuid": "2b1445fe-507d-4d0b-8633-7e7ea3dcc40c",
        "execution": {
          "iopub.execute_input": "2024-12-04T13:09:35.072300Z",
          "iopub.status.busy": "2024-12-04T13:09:35.071598Z",
          "iopub.status.idle": "2024-12-04T13:09:46.817749Z",
          "shell.execute_reply": "2024-12-04T13:09:46.816565Z",
          "shell.execute_reply.started": "2024-12-04T13:09:35.072232Z"
        },
        "id": "b8V36cmgynSD",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install json5 gdown sentence-transformers -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "_cell_guid": "56d8808c-d33b-497f-aa3d-19de2f2023c8",
        "_uuid": "590a47b4-6c5b-4716-8c0a-117716a6bba0",
        "execution": {
          "iopub.execute_input": "2024-12-04T13:09:46.819971Z",
          "iopub.status.busy": "2024-12-04T13:09:46.819688Z",
          "iopub.status.idle": "2024-12-04T13:10:16.172718Z",
          "shell.execute_reply": "2024-12-04T13:10:16.171740Z",
          "shell.execute_reply.started": "2024-12-04T13:09:46.819944Z"
        },
        "id": "YQ3a_27dyOco",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import json5\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import re, time\n",
        "# from sentence_transformers import SentenceTransformer\n",
        "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "#import numpy as np\n",
        "#from utils.general import *\n",
        "#import torch\n",
        "\n",
        "from tree_edit_distance import SqlNode, ratio, parse_sql\n",
        "from sqlalchemy import create_engine\n",
        "from prompting import *\n",
        "from sklearn.utils import shuffle\n",
        "from sqlalchemy import text, Connection\n",
        "from utils.dataset import prepare_column_names, structure_from_connection, IterableDataFrame\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!gdown 1Xjbp207zfCaBxhPgt-STB_RxwNo2TIW2\n",
        "#unzip_file('merged_database_2022-06-10.zip', 'pauq_databases')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "engine = create_engine('sqlite:///main_database.sqlite', echo=False)\n",
        "conn = engine.connect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "prepare_column_names(conn) # Устраняет пробелы в названии столбцов\n",
        "queries = IterableDataFrame(pd.read_excel('NLSQL.xlsx'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import itertools\n",
        "\n",
        "# def recove_table(table : pd.DataFrame, subtable_structure : dict):\n",
        "#         pieces = []\n",
        "#         for col in subtable_structure['columns']:\n",
        "#                 if col in table.columns:\n",
        "#                         pieces.append(table[col])\n",
        "#                 else:\n",
        "#                         pieces.append(pd.DataFrame({col : [None] * table.shape[0]}))\n",
        "\n",
        "#         recovered_table = pd.concat(pieces, axis=1)\n",
        "#         return recovered_table\n",
        "\n",
        "# def SFC(table1 : pd.DataFrame, table2 : pd.DataFrame, subtable_structure : dict):\n",
        "#         foreign_col1 = set(table1.columns) ^ set(subtable_structure['columns'])\n",
        "#         foreign_col2 = set(table2.columns) ^ set(subtable_structure['columns'])\n",
        "        \n",
        "#         if len(foreign_col1) != len(foreign_col2):\n",
        "#                 return 0.0\n",
        "\n",
        "#         right_table1 = recove_table(table1, subtable_structure)\n",
        "#         right_table2 = recove_table(table2, subtable_structure)\n",
        "\n",
        "#         permutations = list(itertools.permutations([i for i in range(len(foreign_col1))]))\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "60baf893-838f-4564-b751-92fdb1ab2a4d",
        "_uuid": "ea5468d0-d708-4c03-aac9-6cca9e60a383",
        "collapsed": false,
        "id": "bbFNaY5A4KVs",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "source": [
        "# Препроцессинг промпта"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "64840261-2c1b-4465-a27f-d7ad5c98cb1b",
        "_uuid": "48755d5c-c9c8-4028-8ff7-a6b5aebc4d9d",
        "execution": {
          "iopub.status.busy": "2024-12-03T12:29:09.956075Z",
          "iopub.status.idle": "2024-12-03T12:29:09.956362Z",
          "shell.execute_reply": "2024-12-03T12:29:09.956242Z",
          "shell.execute_reply.started": "2024-12-03T12:29:09.956227Z"
        },
        "id": "dZjzp_vLfyxw",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "sentence_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "badd3dde-3fb0-433b-9a81-50d83886e96e",
        "_uuid": "8e31e90d-f714-43c9-b231-be1788cbcdc6",
        "execution": {
          "iopub.execute_input": "2024-12-02T18:02:45.231125Z",
          "iopub.status.busy": "2024-12-02T18:02:45.230817Z",
          "iopub.status.idle": "2024-12-02T18:02:45.255546Z",
          "shell.execute_reply": "2024-12-02T18:02:45.254705Z",
          "shell.execute_reply.started": "2024-12-02T18:02:45.231097Z"
        },
        "id": "HBRQjrXdfyxx",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class HuggingFaceModelInference:\n",
        "    def __init__(self, path):\n",
        "        self.path = path\n",
        "        self.evaluated = False\n",
        "        self.is_downloaded = False\n",
        "\n",
        "\n",
        "    def __load_model(self):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self.path, trust_remote_code=True)\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "                    self.path,\n",
        "                    torch_dtype=torch.float16,\n",
        "                    device_map=\"auto\",\n",
        "                    max_memory={0: \"10GiB\", 1: \"10GiB\"},  \n",
        "                    offload_folder=\"./offload\", \n",
        "                    trust_remote_code=True\n",
        "                    )\n",
        "\n",
        "\n",
        "    def evaluate(self, queries : IterableDataFrame, connection : Connection):\n",
        "        if not self.is_downloaded:\n",
        "            self.__load_model()\n",
        "            self.is_downloaded = True\n",
        "\n",
        "\n",
        "        self.model.eval()\n",
        "        logger = []\n",
        "        summary = 0\n",
        "        for query in tqdm(queries):\n",
        "            question = query['question']\n",
        "            gold_sql = query['query']\n",
        "\n",
        "            builder = PromptBuilder(question)\n",
        "            prompt = builder.add_schema_template(connection)\\\n",
        "                             .build_prompt(4)\n",
        "\n",
        "            text = f'''You are an AI programming assistant, utilizing the Deepseek Coder model, developed by Deepseek Company, and you only answer questions related to computer science. For politically sensitive questions, security and privacy issues, and other non-computer science questions, you will refuse to answer.\n",
        "                1. Return ONLY valid SQL query without any explanations\n",
        "                3. Never repeat the answer\n",
        "                4. Format: [SQL]<query>[/SQL]\n",
        "                \n",
        "                ### Instruction:\n",
        "                {prompt}\\n\\n\n",
        "                ### Response:'''\n",
        "            \n",
        "            if self.tokenizer.pad_token is None:\n",
        "                self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "            with torch.inference_mode():  \n",
        "                inputs = self.tokenizer(text,return_tensors=\"pt\").to(self.model.device) \n",
        "\n",
        "                generate_ids = self.model.generate(\n",
        "                                **inputs,\n",
        "                                max_length=2048,\n",
        "                                num_return_sequences=1,\n",
        "                                temperature=0.2, \n",
        "                                top_p=0.95,\n",
        "                                do_sample=True,\n",
        "                                use_cache=True \n",
        "                                )\n",
        "        \n",
        "                output = self.tokenizer.decode(\n",
        "                        generate_ids[0, inputs.input_ids.shape[1]:],\n",
        "                        skip_special_tokens=True\n",
        "                        )\n",
        "\n",
        "            #pred_sql = re.search(r'Response:(.+)', output, re.DOTALL).group(1).strip()\n",
        "            pred_sql =  re.search(r'\\[SQL\\](.*?)\\[\\/SQL\\]', output, re.DOTALL)\n",
        "            pred_sql = pred_sql.group(1).strip() if pred_sql else \"error\"\n",
        "            logger.append({'question' : question, 'pred' : pred_sql, 'gold' : gold_sql})\n",
        "            \n",
        "            try:\n",
        "                df_pred = pd.read_sql(pred_sql, connection)\n",
        "                df_gold = pd.read_sql(gold_sql, connection)\n",
        "                summary += table_similarity(df_pred, df_gold, mode='flexible')\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        self.summary = summary\n",
        "        self.queries_count = len(queries)\n",
        "        self.logger = logger\n",
        "        self.evaluated = True\n",
        "\n",
        "\n",
        "    def accuracy(self):\n",
        "        \"\"\"\n",
        "        Значение метрики Accuracy для последнего запуска модели\n",
        "        \"\"\"\n",
        "\n",
        "        if not self.evaluated:\n",
        "            raise Exception('Model was not been evaluated')\n",
        "        \n",
        "        return self.summary / self.queries_count\n",
        "\n",
        "\n",
        "    def TED(self):\n",
        "        \"\"\"\n",
        "        Значение метрики Tree Edit Distance для последнего запуска модели\n",
        "        \"\"\"\n",
        "\n",
        "        if not self.evaluated:\n",
        "            raise Exception('Model was not been evaluated')\n",
        "        \n",
        "        summary = 0\n",
        "        for sample in self.logger:\n",
        "            try:\n",
        "                pred_root = parse_sql(sample['pred'])\n",
        "                gold_root = parse_sql(sample['gold'])\n",
        "                summary += ratio(pred_root, gold_root)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        return summary / self.queries_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2290c3dd-c7b0-40df-97c4-6a91dadca036",
        "_uuid": "7e53bbc2-eb78-408c-899c-9b951b7efad4",
        "execution": {
          "iopub.execute_input": "2024-12-02T16:15:04.538483Z",
          "iopub.status.busy": "2024-12-02T16:15:04.538085Z",
          "iopub.status.idle": "2024-12-02T16:15:04.543620Z",
          "shell.execute_reply": "2024-12-02T16:15:04.542578Z",
          "shell.execute_reply.started": "2024-12-02T16:15:04.538450Z"
        },
        "id": "dcQJKD8Nfyxz",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def dump_inference(name: str, exec_time: list, sql_sim, acc):\n",
        "    dump = json5.dumps({\n",
        "        'name': name,\n",
        "        'exec_time': exec_time,\n",
        "        'sql_similarity': str(sql_sim),\n",
        "        'accuracy': str(acc)\n",
        "    })\n",
        "    with open(f'{name}_dump.txt', 'w') as w:\n",
        "        w.write(dump)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "59e279e6-9308-465d-aad6-7fa856d74ad2",
        "_uuid": "f9b0239a-cfac-4e3e-8b90-0e9d6ee06664",
        "collapsed": false,
        "id": "OXTC7kCufyx0",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "source": [
        "## 1. SQLCoder 7b https://huggingface.co/defog/sqlcoder-7b-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "27adee9a-3a22-4869-a3a6-a5d9b84fdafd",
        "_uuid": "02b26db7-9f82-4958-bd91-e60dc1e4c969",
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2024-12-02T18:02:45.258207Z",
          "iopub.status.busy": "2024-12-02T18:02:45.257843Z",
          "iopub.status.idle": "2024-12-02T18:10:00.680821Z",
          "shell.execute_reply": "2024-12-02T18:10:00.679883Z",
          "shell.execute_reply.started": "2024-12-02T18:02:45.258165Z"
        },
        "id": "vCQKMr7_fyx0",
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "sqlcoder = HuggingFaceModelInference('defog/sqlcoder-7b-2')\n",
        "sqlcoder.evaluate(shuffle(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2024-12-02T18:11:26.985804Z",
          "iopub.status.busy": "2024-12-02T18:11:26.984881Z",
          "iopub.status.idle": "2024-12-02T18:11:28.237055Z",
          "shell.execute_reply": "2024-12-02T18:11:28.236120Z",
          "shell.execute_reply.started": "2024-12-02T18:11:26.985769Z"
        },
        "id": "aM5iPZbKfyx1",
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "sqlcoder.accuracy(), sqlcoder.sql_similarity(), np.mean(sqlcoder.exec_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2024-12-02T18:11:45.734500Z",
          "iopub.status.busy": "2024-12-02T18:11:45.734136Z",
          "iopub.status.idle": "2024-12-02T18:11:45.741494Z",
          "shell.execute_reply": "2024-12-02T18:11:45.740679Z",
          "shell.execute_reply.started": "2024-12-02T18:11:45.734468Z"
        },
        "id": "dbrujfaxfyx2",
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "sqlcoder.logger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DeepSeek coder 6.7b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "deepseek = HuggingFaceModelInference('deepseek-ai/deepseek-coder-6.7b-instruct')\n",
        "deepseek.evaluate(shuffle(queries.as_list())[:10], conn) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d55558bc-4b00-4394-bc4f-c0073a11401d",
        "_uuid": "4ae33630-d334-42a2-8cb6-b598829eff96",
        "collapsed": false,
        "id": "NeSXnH5efyx2",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "source": [
        "## 3. Chat2DB 7b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6331cae7-1f53-4810-bbac-16746766a115",
        "_uuid": "df11395b-e166-4e60-a8c1-177616885682",
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2024-12-02T17:12:09.427825Z",
          "iopub.status.busy": "2024-12-02T17:12:09.427437Z",
          "iopub.status.idle": "2024-12-02T17:13:14.571814Z",
          "shell.execute_reply": "2024-12-02T17:13:14.570891Z",
          "shell.execute_reply.started": "2024-12-02T17:12:09.427793Z"
        },
        "id": "g2R-FoySfyx2",
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# chat2db = HuggingFaceModelInference('Chat2DB/Chat2DB-SQL-7B')\n",
        "# chat2db.evaluate(shuffle(dataset)[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2024-12-02T17:13:24.942041Z",
          "iopub.status.busy": "2024-12-02T17:13:24.941195Z",
          "iopub.status.idle": "2024-12-02T17:13:25.801628Z",
          "shell.execute_reply": "2024-12-02T17:13:25.800743Z",
          "shell.execute_reply.started": "2024-12-02T17:13:24.942006Z"
        },
        "id": "hMmXGF2efyx3",
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# chat2db.accuracy(), chat2db.sql_similarity(), np.mean(chat2db.exec_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4fa7c30a-25e6-4896-a7ef-a48677e4a609",
        "_uuid": "9851857f-6885-4d68-b229-64584ef63b7a",
        "id": "J8Fqx7jtfyx3",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# dump_inference('Chat2DB-SQL-7B', chat2db.exec_time, chat2db.sql_similarity(), chat2db.accuracy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "36e6679e-f787-4878-9ece-778d696f902a",
        "_uuid": "fb512d0f-8426-42c4-b47f-8842ea420b28",
        "collapsed": false,
        "id": "tYwLcup9fyx4",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "source": [
        "## 5. DuckDB-NSQL 7b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2d0f45a8-7c98-432e-89ab-59345f8f6888",
        "_uuid": "dab98270-0c45-4157-828c-4fc879b8969a",
        "execution": {
          "iopub.execute_input": "2024-12-02T17:21:47.697990Z",
          "iopub.status.busy": "2024-12-02T17:21:47.697359Z",
          "iopub.status.idle": "2024-12-02T17:21:47.701968Z",
          "shell.execute_reply": "2024-12-02T17:21:47.701064Z",
          "shell.execute_reply.started": "2024-12-02T17:21:47.697946Z"
        },
        "id": "Tot4dlxMfyx4",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# duckdb = HuggingFaceModelInference('motherduckdb/DuckDB-NSQL-7B-v0.1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2024-12-02T17:32:16.001291Z",
          "iopub.status.busy": "2024-12-02T17:32:16.000509Z",
          "iopub.status.idle": "2024-12-02T17:33:47.564041Z",
          "shell.execute_reply": "2024-12-02T17:33:47.562937Z",
          "shell.execute_reply.started": "2024-12-02T17:32:16.001257Z"
        },
        "id": "hPpuGQcSfyx4",
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# duckdb.evaluate(shuffle(dataset)[:30])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-02T17:39:31.191655Z",
          "iopub.status.busy": "2024-12-02T17:39:31.190792Z",
          "iopub.status.idle": "2024-12-02T17:39:32.556694Z",
          "shell.execute_reply": "2024-12-02T17:39:32.555918Z",
          "shell.execute_reply.started": "2024-12-02T17:39:31.191610Z"
        },
        "id": "8Q31HSR_fyx4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# duckdb.accuracy(), duckdb.sql_similarity(), np.mean(duckdb.exec_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "911306e3-b047-451a-abcf-00dbf37fe1c7",
        "_uuid": "1ef8f63d-9d86-4070-9e67-c10675859a72",
        "collapsed": false,
        "id": "iyJhh7Srfyx6",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "source": [
        "## Прочее"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "823de476-d607-4c57-9d9e-90c55ecb6b3b",
        "_uuid": "d845407a-9c1d-459b-8c9c-ec713618828e",
        "execution": {
          "iopub.execute_input": "2024-12-02T16:44:21.761572Z",
          "iopub.status.busy": "2024-12-02T16:44:21.760909Z",
          "iopub.status.idle": "2024-12-02T16:44:24.122804Z",
          "shell.execute_reply": "2024-12-02T16:44:24.121915Z",
          "shell.execute_reply.started": "2024-12-02T16:44:21.761539Z"
        },
        "id": "P7KlZTlxfyx6",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from numba import cuda\n",
        "import gc\n",
        "cuda.devices.gpus[0].reset()\n",
        "cuda.devices.gpus[1].reset()\n",
        "gc.collect()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 6212694,
          "sourceId": 10078210,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30787,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
